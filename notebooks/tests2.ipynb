{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from dataset import TinyShakespeare\n",
    "from jax_utils import print_param_names\n",
    "from layers import cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MetalDevice(id=0, process_index=0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1212\n",
    "rnd_key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the autoregressive loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tiny Shakespeare dataset...\n",
      "Loaded Tiny Shakespeare dataset\n"
     ]
    }
   ],
   "source": [
    "dataset = TinyShakespeare(rnd_key, batch_size=16, seq_len=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34848, 32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 128\n",
    "num_heads = 8\n",
    "num_layers = 3\n",
    "d_ff = 512\n",
    "batch_size = 128\n",
    "n_vocab = dataset.n_tokens\n",
    "seq_len = 32\n",
    "n_epochs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import create_autoregressive_transformer\n",
    "\n",
    "transformer_model, params = create_autoregressive_transformer(rnd_key, num_layers, num_heads, \n",
    "                                                              d_model, d_ff, n_vocab, \n",
    "                                                              fast=False, lambda_pe= 1 / d_model ** 0.5)\n",
    "def transformer_loss(params, x):\n",
    "    output = transformer_model(params, x)\n",
    "    x_shape = x.shape\n",
    "    # print(\"x_shape\", x_shape)\n",
    "    # To make sure the output has the same shape as x\n",
    "    x = x.reshape(*x_shape, -1)\n",
    "    # Vmap to apply the loss function along the sequence\n",
    "    return jax.vmap(cross_entropy_loss, in_axes=[0, 0])(output[:-1], x[1:]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = jax.jit(jax.vmap(transformer_model, in_axes=(None, 0), out_axes=0))\n",
    "# Vmap over the batch axis\n",
    "batched_loss = jax.jit(jax.vmap(transformer_loss, in_axes=(None, 0), out_axes=0))\n",
    "\n",
    "def get_loss(params, seq):\n",
    "    return batched_loss(params, seq).mean()\n",
    "\n",
    "grad_loss_fn = jax.value_and_grad(get_loss, argnums=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(8.417043, dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dataset.data[0:16]\n",
    "x_shape = x.shape\n",
    "output = model(params, x)\n",
    "loss, grad = grad_loss_fn(params, x)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test attention\n",
    "from layers import attention\n",
    "d_k = d_model // num_heads\n",
    "rng, q_key, k_key, v_key = jax.random.split(rnd_key, 4)\n",
    "q = jax.random.normal(q_key, (batch_size, seq_len, num_heads, d_k))\n",
    "k = jax.random.normal(k_key, (batch_size, seq_len, num_heads, d_k))\n",
    "v = jax.random.normal(v_key, (batch_size, seq_len, num_heads, d_k))\n",
    "\n",
    "# Move the heads to the batch dimension\n",
    "q, k, v = map(lambda x: x.transpose((0, 2, 1, 3)), (q, k, v))\n",
    "# Repeat along the batch dimension\n",
    "output = jax.vmap(attention, in_axes=(0, 0, 0, None), out_axes=(0))(q, k, v, None)\n",
    "assert output.shape == (batch_size, num_heads, seq_len, d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.n_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def sample(model: Callable, params: dict, seq: jnp.ndarray, length: int = 20):\n",
    "    \"\"\"\n",
    "    ### Sample\n",
    "\n",
    "    The starting sequence is given by `seq` and we greedily sample `length` tokens\n",
    "    \"\"\"\n",
    "    for i in range(length):\n",
    "        # Sample the highest probability token\n",
    "        idx = jnp.argmax(model(params, seq)[-1])\n",
    "        # Add it to the sequence\n",
    "        seq = jnp.concatenate((seq, idx[None]))\n",
    "        # print(seq)\n",
    "\n",
    "    # Return the sampled sequence\n",
    "    return seq\n",
    "\n",
    "def evaluate_model(model, params):\n",
    "    prompt = [dataset.stoi[c] for c in 'It is']\n",
    "    sampled = sample(model, params, jnp.array(prompt))[len(prompt):]\n",
    "    sampled = ''.join([dataset.itos[i] for i in sampled])\n",
    "    print(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Loss: 8.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [08:09,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000: Loss: 3.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [16:22,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000: Loss: 3.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2178it [17:48,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 3.096646308898926\n",
      " t t t t t t t t t t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Loss: 3.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [07:48,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000: Loss: 2.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [15:33,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000: Loss: 2.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2178it [16:56,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 2.736133575439453\n",
      " the the the the the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Loss: 2.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [07:44,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000: Loss: 2.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [15:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000: Loss: 2.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2178it [17:01,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 2.6039538383483887\n",
      " anou I ie.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Loss: 2.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:54,  2.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kaushalya/code/jaxformer/notebooks/tests2.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaushalya/code/jaxformer/notebooks/tests2.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaushalya/code/jaxformer/notebooks/tests2.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Update parameters\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kaushalya/code/jaxformer/notebooks/tests2.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m updates, opt_state \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39;49mupdate(grads, opt_state, params)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaushalya/code/jaxformer/notebooks/tests2.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m params \u001b[39m=\u001b[39m optax\u001b[39m.\u001b[39mapply_updates(params, updates)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaushalya/code/jaxformer/notebooks/tests2.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# params = optimizer.step(params, grads)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_py39/lib/python3.9/site-packages/optax/_src/combine.py:59\u001b[0m, in \u001b[0;36mchain.<locals>.update_fn\u001b[0;34m(updates, state, params, **extra_args)\u001b[0m\n\u001b[1;32m     57\u001b[0m new_state \u001b[39m=\u001b[39m []\n\u001b[1;32m     58\u001b[0m \u001b[39mfor\u001b[39;00m s, fn \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(state, update_fns):\n\u001b[0;32m---> 59\u001b[0m   updates, new_s \u001b[39m=\u001b[39m fn(updates, s, params, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_args)\n\u001b[1;32m     60\u001b[0m   new_state\u001b[39m.\u001b[39mappend(new_s)\n\u001b[1;32m     61\u001b[0m \u001b[39mreturn\u001b[39;00m updates, \u001b[39mtuple\u001b[39m(new_state)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_py39/lib/python3.9/site-packages/optax/_src/base.py:311\u001b[0m, in \u001b[0;36mwith_extra_args_support.<locals>.update\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate\u001b[39m(updates, state, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_args):\n\u001b[1;32m    310\u001b[0m   \u001b[39mdel\u001b[39;00m extra_args\n\u001b[0;32m--> 311\u001b[0m   \u001b[39mreturn\u001b[39;00m tx\u001b[39m.\u001b[39;49mupdate(updates, state, params)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_py39/lib/python3.9/site-packages/optax/_src/transform.py:347\u001b[0m, in \u001b[0;36mscale_by_adam.<locals>.update_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    345\u001b[0m mu_hat \u001b[39m=\u001b[39m bias_correction(mu, b1, count_inc)\n\u001b[1;32m    346\u001b[0m nu_hat \u001b[39m=\u001b[39m bias_correction(nu, b2, count_inc)\n\u001b[0;32m--> 347\u001b[0m updates \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mtree_util\u001b[39m.\u001b[39;49mtree_map(\n\u001b[1;32m    348\u001b[0m     \u001b[39mlambda\u001b[39;49;00m m, v: m \u001b[39m/\u001b[39;49m (jnp\u001b[39m.\u001b[39;49msqrt(v \u001b[39m+\u001b[39;49m eps_root) \u001b[39m+\u001b[39;49m eps), mu_hat, nu_hat)\n\u001b[1;32m    349\u001b[0m mu \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mcast_tree(mu, mu_dtype)\n\u001b[1;32m    350\u001b[0m \u001b[39mreturn\u001b[39;00m updates, ScaleByAdamState(count\u001b[39m=\u001b[39mcount_inc, mu\u001b[39m=\u001b[39mmu, nu\u001b[39m=\u001b[39mnu)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_py39/lib/python3.9/site-packages/jax/_src/tree_util.py:210\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    208\u001b[0m leaves, treedef \u001b[39m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    209\u001b[0m all_leaves \u001b[39m=\u001b[39m [leaves] \u001b[39m+\u001b[39m [treedef\u001b[39m.\u001b[39mflatten_up_to(r) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m rest]\n\u001b[0;32m--> 210\u001b[0m \u001b[39mreturn\u001b[39;00m treedef\u001b[39m.\u001b[39;49munflatten(f(\u001b[39m*\u001b[39;49mxs) \u001b[39mfor\u001b[39;49;00m xs \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49mall_leaves))\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_py39/lib/python3.9/site-packages/jax/_src/tree_util.py:210\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    208\u001b[0m leaves, treedef \u001b[39m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    209\u001b[0m all_leaves \u001b[39m=\u001b[39m [leaves] \u001b[39m+\u001b[39m [treedef\u001b[39m.\u001b[39mflatten_up_to(r) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m rest]\n\u001b[0;32m--> 210\u001b[0m \u001b[39mreturn\u001b[39;00m treedef\u001b[39m.\u001b[39munflatten(f(\u001b[39m*\u001b[39;49mxs) \u001b[39mfor\u001b[39;00m xs \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_py39/lib/python3.9/site-packages/optax/_src/transform.py:348\u001b[0m, in \u001b[0;36mscale_by_adam.<locals>.update_fn.<locals>.<lambda>\u001b[0;34m(m, v)\u001b[0m\n\u001b[1;32m    345\u001b[0m mu_hat \u001b[39m=\u001b[39m bias_correction(mu, b1, count_inc)\n\u001b[1;32m    346\u001b[0m nu_hat \u001b[39m=\u001b[39m bias_correction(nu, b2, count_inc)\n\u001b[1;32m    347\u001b[0m updates \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mtree_map(\n\u001b[0;32m--> 348\u001b[0m     \u001b[39mlambda\u001b[39;00m m, v: m \u001b[39m/\u001b[39m (jnp\u001b[39m.\u001b[39msqrt(v \u001b[39m+\u001b[39;49m eps_root) \u001b[39m+\u001b[39m eps), mu_hat, nu_hat)\n\u001b[1;32m    349\u001b[0m mu \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mcast_tree(mu, mu_dtype)\n\u001b[1;32m    350\u001b[0m \u001b[39mreturn\u001b[39;00m updates, ScaleByAdamState(count\u001b[39m=\u001b[39mcount_inc, mu\u001b[39m=\u001b[39mmu, nu\u001b[39m=\u001b[39mnu)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_py39/lib/python3.9/site-packages/jax/_src/numpy/array_methods.py:258\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    256\u001b[0m args \u001b[39m=\u001b[39m (other, \u001b[39mself\u001b[39m) \u001b[39mif\u001b[39;00m swap \u001b[39melse\u001b[39;00m (\u001b[39mself\u001b[39m, other)\n\u001b[1;32m    257\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 258\u001b[0m   \u001b[39mreturn\u001b[39;00m binary_op(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _rejected_binop_types):\n\u001b[1;32m    260\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsupported operand type(s) for \u001b[39m\u001b[39m{\u001b[39;00mopchar\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(args[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(args[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optax\n",
    "from optim import Adam\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = optax.adamw(learning_rate)\n",
    "opt_state = optimizer.init(params)\n",
    "# Create optimizer\n",
    "# optimizer = Adam(params)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    losses = []\n",
    "    for i, batch in tqdm(enumerate(dataset)):\n",
    "        loss, grads = grad_loss_fn(params, batch)\n",
    "        losses.append(loss)\n",
    "        # Update parameters\n",
    "        updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        # params = optimizer.step(params, grads)\n",
    "        if i==0 or (i+1)%1000==0:\n",
    "            print(f\"{i+1}: Loss: {loss:.2f}\")\n",
    "    print(f'Epoch {epoch} loss: {jnp.mean(loss)}')\n",
    "    evaluate_model(transformer_model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ssssssssGddddddddd d'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 65)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = transformer_model(params, jnp.array(prompt))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(57, dtype=int32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.argmax(output[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.array([prompt]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding\n",
      "embedding.emb\n",
      "embedding.pos\n",
      "layers\n",
      "layers.layer_0\n",
      "layers.layer_0.ff\n",
      "layers.layer_0.ff.ff1\n",
      "layers.layer_0.ff.ff1.b\n",
      "layers.layer_0.ff.ff1.w\n",
      "layers.layer_0.ff.ff2\n",
      "layers.layer_0.ff.ff2.b\n",
      "layers.layer_0.ff.ff2.w\n",
      "layers.layer_0.heads\n",
      "layers.layer_0.heads.w_k\n",
      "layers.layer_0.heads.w_k.b\n",
      "layers.layer_0.heads.w_k.w\n",
      "layers.layer_0.heads.w_q\n",
      "layers.layer_0.heads.w_q.b\n",
      "layers.layer_0.heads.w_q.w\n",
      "layers.layer_0.heads.w_v\n",
      "layers.layer_0.heads.w_v.b\n",
      "layers.layer_0.heads.w_v.w\n",
      "layers.layer_0.ln1\n",
      "layers.layer_0.ln1.bias\n",
      "layers.layer_0.ln1.gain\n",
      "layers.layer_0.ln2\n",
      "layers.layer_0.ln2.bias\n",
      "layers.layer_0.ln2.gain\n",
      "layers.layer_0.output\n",
      "layers.layer_0.output.b\n",
      "layers.layer_0.output.w\n",
      "layers.layer_1\n",
      "layers.layer_1.ff\n",
      "layers.layer_1.ff.ff1\n",
      "layers.layer_1.ff.ff1.b\n",
      "layers.layer_1.ff.ff1.w\n",
      "layers.layer_1.ff.ff2\n",
      "layers.layer_1.ff.ff2.b\n",
      "layers.layer_1.ff.ff2.w\n",
      "layers.layer_1.heads\n",
      "layers.layer_1.heads.w_k\n",
      "layers.layer_1.heads.w_k.b\n",
      "layers.layer_1.heads.w_k.w\n",
      "layers.layer_1.heads.w_q\n",
      "layers.layer_1.heads.w_q.b\n",
      "layers.layer_1.heads.w_q.w\n",
      "layers.layer_1.heads.w_v\n",
      "layers.layer_1.heads.w_v.b\n",
      "layers.layer_1.heads.w_v.w\n",
      "layers.layer_1.ln1\n",
      "layers.layer_1.ln1.bias\n",
      "layers.layer_1.ln1.gain\n",
      "layers.layer_1.ln2\n",
      "layers.layer_1.ln2.bias\n",
      "layers.layer_1.ln2.gain\n",
      "layers.layer_1.output\n",
      "layers.layer_1.output.b\n",
      "layers.layer_1.output.w\n",
      "layers.layer_2\n",
      "layers.layer_2.ff\n",
      "layers.layer_2.ff.ff1\n",
      "layers.layer_2.ff.ff1.b\n",
      "layers.layer_2.ff.ff1.w\n",
      "layers.layer_2.ff.ff2\n",
      "layers.layer_2.ff.ff2.b\n",
      "layers.layer_2.ff.ff2.w\n",
      "layers.layer_2.heads\n",
      "layers.layer_2.heads.w_k\n",
      "layers.layer_2.heads.w_k.b\n",
      "layers.layer_2.heads.w_k.w\n",
      "layers.layer_2.heads.w_q\n",
      "layers.layer_2.heads.w_q.b\n",
      "layers.layer_2.heads.w_q.w\n",
      "layers.layer_2.heads.w_v\n",
      "layers.layer_2.heads.w_v.b\n",
      "layers.layer_2.heads.w_v.w\n",
      "layers.layer_2.ln1\n",
      "layers.layer_2.ln1.bias\n",
      "layers.layer_2.ln1.gain\n",
      "layers.layer_2.ln2\n",
      "layers.layer_2.ln2.bias\n",
      "layers.layer_2.ln2.gain\n",
      "layers.layer_2.output\n",
      "layers.layer_2.output.b\n",
      "layers.layer_2.output.w\n",
      "ln\n",
      "ln.bias\n",
      "ln.gain\n",
      "output\n",
      "output.b\n",
      "output.w\n"
     ]
    }
   ],
   "source": [
    "print_param_names(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative model designs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(params):    \n",
    "    def forward(x):\n",
    "        return x @ params\n",
    "    return forward\n",
    "\n",
    "\n",
    "def mlp2(d_in, d_out):\n",
    "    # Initialize parameters\n",
    "    params = jax.random.normal(rnd_key, (d_in, d_out))\n",
    "    def forward(x, params=params):\n",
    "        return x @ params\n",
    "    # There is no other method to get the parameters\n",
    "    return forward, params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model that takes parameters as an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "d_in, d_out = 8, 16\n",
    "x = jnp.ones((n, d_in))\n",
    "rng, rn2 = jax.random.split(rnd_key)\n",
    "params = jax.random.normal(rnd_key, (d_in, d_out))\n",
    "\n",
    "model = mlp(params)\n",
    "out = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the second model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params = mlp2(d_in, d_out)\n",
    "out2 = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert jnp.all(out == out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested `vmap`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 8,  9],\n",
       "       [ 9, 10],\n",
       "       [10, 11],\n",
       "       [11, 12],\n",
       "       [12, 13],\n",
       "       [13, 14],\n",
       "       [14, 15],\n",
       "       [15, 16],\n",
       "       [16, 17],\n",
       "       [17, 18]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum(x, y):\n",
    "    return x + y\n",
    "\n",
    "x = jnp.arange(10)\n",
    "y = jnp.arange(8, 10)\n",
    "\n",
    "jax.vmap(jax.vmap(sum, in_axes=(None, 0)), in_axes=(0, None))(x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
