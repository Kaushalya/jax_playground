{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from dataset import TinyShakespeare\n",
    "from jax_utils import print_param_names\n",
    "from transformer_functional import cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1212\n",
    "rnd_key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the autoregressive loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tiny Shakespeare dataset...\n",
      "Loaded Tiny Shakespeare dataset\n"
     ]
    }
   ],
   "source": [
    "dataset = TinyShakespeare(rnd_key, batch_size=16, seq_len=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34848, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 128\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "d_ff = 256\n",
    "n_vocab = dataset.n_tokens\n",
    "n_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import create_autoregressive_transformer\n",
    "\n",
    "transformer_model, params = create_autoregressive_transformer(rnd_key, num_layers, num_heads, d_model, d_ff, n_vocab)\n",
    "\n",
    "def transformer_loss(params, x):\n",
    "    output = transformer_model(params, x)\n",
    "    return jax.vmap(cross_entropy_loss, in_axes=(0, 0))(output, x).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = jax.jit(jax.vmap(transformer_model, in_axes=(None, 0), out_axes=0))\n",
    "batched_loss = jax.jit(jax.vmap(transformer_loss, in_axes=(None, 0), out_axes=0))\n",
    "\n",
    "def get_loss(params, seq):\n",
    "    return batched_loss(params, seq).mean()\n",
    "\n",
    "grad_loss_fn = jax.value_and_grad(get_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dot_general requires contracting dimensions to have the same shape, got (32,) and (128,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/kaushalya/code/jaxformer/notebooks/tests2.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kaushalya/code/jaxformer/notebooks/tests2.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mdata[\u001b[39m0\u001b[39m:\u001b[39m4\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kaushalya/code/jaxformer/notebooks/tests2.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m output \u001b[39m=\u001b[39m model(params, x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kaushalya/code/jaxformer/notebooks/tests2.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m loss, grad \u001b[39m=\u001b[39m grad_loss_fn(params, x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kaushalya/code/jaxformer/notebooks/tests2.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m loss\n",
      "    \u001b[0;31m[... skipping hidden 15 frame]\u001b[0m\n",
      "File \u001b[0;32m~/code/jaxformer/notebooks/../layers.py:215\u001b[0m, in \u001b[0;36mcreate_autoregressive_transformer.<locals>.forward\u001b[0;34m(params, x)\u001b[0m\n\u001b[1;32m    213\u001b[0m layer_params \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mlayers\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    214\u001b[0m \u001b[39mfor\u001b[39;00m mha_fn, layer_param \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(multi_head_attentions, layer_params\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m--> 215\u001b[0m     x \u001b[39m=\u001b[39m mha_fn(layer_param, x, mask\u001b[39m=\u001b[39;49mmask)\n\u001b[1;32m    216\u001b[0m x \u001b[39m=\u001b[39m layernorm(params[\u001b[39m\"\u001b[39m\u001b[39mln\u001b[39m\u001b[39m\"\u001b[39m], x)\n\u001b[1;32m    217\u001b[0m x \u001b[39m=\u001b[39m linear_output(params[\u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m], x)\n",
      "File \u001b[0;32m~/code/jaxformer/notebooks/../layers.py:135\u001b[0m, in \u001b[0;36mcreate_multi_head_attention.<locals>.forward\u001b[0;34m(params, x, mask)\u001b[0m\n\u001b[1;32m    132\u001b[0m t1 \u001b[39m=\u001b[39m layernorm1(params[\u001b[39m\"\u001b[39m\u001b[39mln1\u001b[39m\u001b[39m\"\u001b[39m], x)\n\u001b[1;32m    133\u001b[0m \u001b[39m# Run attention layers in parallel\u001b[39;00m\n\u001b[1;32m    134\u001b[0m t1 \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mconcatenate(\n\u001b[0;32m--> 135\u001b[0m     [\n\u001b[1;32m    136\u001b[0m         attn(attn_params, t1, mask\u001b[39m=\u001b[39mmask)\n\u001b[1;32m    137\u001b[0m         \u001b[39mfor\u001b[39;00m attn, attn_params \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(heads, head_params\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m    138\u001b[0m     ],\n\u001b[1;32m    139\u001b[0m     axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    141\u001b[0m x \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m linear_output(params[\u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m], t1)\n\u001b[1;32m    142\u001b[0m t2 \u001b[39m=\u001b[39m layernorm2(params[\u001b[39m\"\u001b[39m\u001b[39mln2\u001b[39m\u001b[39m\"\u001b[39m], x)\n",
      "File \u001b[0;32m~/code/jaxformer/notebooks/../layers.py:136\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    132\u001b[0m t1 \u001b[39m=\u001b[39m layernorm1(params[\u001b[39m\"\u001b[39m\u001b[39mln1\u001b[39m\u001b[39m\"\u001b[39m], x)\n\u001b[1;32m    133\u001b[0m \u001b[39m# Run attention layers in parallel\u001b[39;00m\n\u001b[1;32m    134\u001b[0m t1 \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mconcatenate(\n\u001b[1;32m    135\u001b[0m     [\n\u001b[0;32m--> 136\u001b[0m         attn(attn_params, t1, mask\u001b[39m=\u001b[39;49mmask)\n\u001b[1;32m    137\u001b[0m         \u001b[39mfor\u001b[39;00m attn, attn_params \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(heads, head_params\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m    138\u001b[0m     ],\n\u001b[1;32m    139\u001b[0m     axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    141\u001b[0m x \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m linear_output(params[\u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m], t1)\n\u001b[1;32m    142\u001b[0m t2 \u001b[39m=\u001b[39m layernorm2(params[\u001b[39m\"\u001b[39m\u001b[39mln2\u001b[39m\u001b[39m\"\u001b[39m], x)\n",
      "File \u001b[0;32m~/code/jaxformer/notebooks/../layers.py:89\u001b[0m, in \u001b[0;36mcreate_attention.<locals>.forward\u001b[0;34m(params, x, mask)\u001b[0m\n\u001b[1;32m     87\u001b[0m k \u001b[39m=\u001b[39m linear_k(params[\u001b[39m\"\u001b[39m\u001b[39mw_k\u001b[39m\u001b[39m\"\u001b[39m], x)\n\u001b[1;32m     88\u001b[0m v \u001b[39m=\u001b[39m linear_v(params[\u001b[39m\"\u001b[39m\u001b[39mw_v\u001b[39m\u001b[39m\"\u001b[39m], x)\n\u001b[0;32m---> 89\u001b[0m \u001b[39mreturn\u001b[39;00m linear_output(params[\u001b[39m\"\u001b[39;49m\u001b[39moutput\u001b[39;49m\u001b[39m\"\u001b[39;49m], attention(q, k, v, mask\u001b[39m=\u001b[39;49mmask))\n",
      "File \u001b[0;32m~/code/jaxformer/notebooks/../layers.py:62\u001b[0m, in \u001b[0;36mcreate_linear.<locals>.forward\u001b[0;34m(params, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(params: \u001b[39mdict\u001b[39m, x: jnp\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m jnp\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m---> 62\u001b[0m     \u001b[39mreturn\u001b[39;00m x \u001b[39m@\u001b[39;49m params[\u001b[39m\"\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m+\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_py39/lib/python3.9/site-packages/jax/_src/numpy/array_methods.py:723\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mop\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 723\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maval, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mname\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_py39/lib/python3.9/site-packages/jax/_src/numpy/array_methods.py:256\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    254\u001b[0m args \u001b[39m=\u001b[39m (other, \u001b[39mself\u001b[39m) \u001b[39mif\u001b[39;00m swap \u001b[39melse\u001b[39;00m (\u001b[39mself\u001b[39m, other)\n\u001b[1;32m    255\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 256\u001b[0m   \u001b[39mreturn\u001b[39;00m binary_op(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    257\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _rejected_binop_types):\n\u001b[1;32m    258\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsupported operand type(s) for \u001b[39m\u001b[39m{\u001b[39;00mopchar\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(args[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(args[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_py39/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:3134\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(a, b, precision)\u001b[0m\n\u001b[1;32m   3132\u001b[0m a \u001b[39m=\u001b[39m lax\u001b[39m.\u001b[39msqueeze(a, \u001b[39mtuple\u001b[39m(a_squeeze))\n\u001b[1;32m   3133\u001b[0m b \u001b[39m=\u001b[39m lax\u001b[39m.\u001b[39msqueeze(b, \u001b[39mtuple\u001b[39m(b_squeeze))\n\u001b[0;32m-> 3134\u001b[0m out \u001b[39m=\u001b[39m lax\u001b[39m.\u001b[39;49mdot_general(\n\u001b[1;32m   3135\u001b[0m   a, b, (((ndim(a) \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,), (ndim(b) \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m b_is_mat,)), (a_batch, b_batch)),\n\u001b[1;32m   3136\u001b[0m   precision\u001b[39m=\u001b[39;49mprecision)\n\u001b[1;32m   3137\u001b[0m \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39mtranspose(out, perm)\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_py39/lib/python3.9/site-packages/jax/_src/lax/lax.py:2508\u001b[0m, in \u001b[0;36m_dot_general_shape_rule\u001b[0;34m(lhs, rhs, dimension_numbers, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m   2505\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m core\u001b[39m.\u001b[39mdefinitely_equal_shape(lhs_contracting_shape, rhs_contracting_shape):\n\u001b[1;32m   2506\u001b[0m   msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mdot_general requires contracting dimensions to have the same \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2507\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mshape, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2508\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg\u001b[39m.\u001b[39mformat(lhs_contracting_shape, rhs_contracting_shape))\n\u001b[1;32m   2510\u001b[0m \u001b[39mreturn\u001b[39;00m _dot_general_shape_computation(lhs\u001b[39m.\u001b[39mshape, rhs\u001b[39m.\u001b[39mshape, dimension_numbers)\n",
      "\u001b[0;31mTypeError\u001b[0m: dot_general requires contracting dimensions to have the same shape, got (32,) and (128,)."
     ]
    }
   ],
   "source": [
    "x = dataset.data[0:4]\n",
    "output = model(params, x)\n",
    "loss, grad = grad_loss_fn(params, x)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Loss: 8.85\n",
      "2: Loss: 8.87\n",
      "3: Loss: 8.66\n",
      "4: Loss: 7.78\n",
      "5: Loss: 8.25\n",
      "6: Loss: 7.77\n",
      "7: Loss: 7.60\n",
      "8: Loss: 7.20\n",
      "9: Loss: 6.88\n",
      "10: Loss: 6.44\n",
      "11: Loss: 6.67\n",
      "12: Loss: 6.08\n",
      "13: Loss: 6.02\n",
      "14: Loss: 5.73\n",
      "15: Loss: 5.43\n",
      "16: Loss: 5.43\n",
      "17: Loss: 5.07\n",
      "18: Loss: 4.96\n",
      "19: Loss: 4.81\n",
      "20: Loss: 4.92\n",
      "21: Loss: 4.70\n",
      "22: Loss: 4.45\n",
      "23: Loss: 4.37\n",
      "24: Loss: 4.27\n",
      "25: Loss: 4.22\n",
      "26: Loss: 3.96\n",
      "27: Loss: 4.10\n",
      "28: Loss: 3.98\n",
      "29: Loss: 3.93\n",
      "30: Loss: 4.00\n",
      "31: Loss: 3.70\n",
      "32: Loss: 3.80\n",
      "33: Loss: 3.61\n",
      "34: Loss: 3.69\n",
      "35: Loss: 3.48\n",
      "36: Loss: 3.65\n",
      "37: Loss: 3.64\n",
      "38: Loss: 3.53\n",
      "39: Loss: 3.58\n",
      "40: Loss: 3.58\n",
      "41: Loss: 3.61\n",
      "42: Loss: 3.34\n",
      "43: Loss: 3.35\n",
      "44: Loss: 3.37\n",
      "45: Loss: 3.40\n",
      "46: Loss: 3.46\n",
      "47: Loss: 3.42\n",
      "48: Loss: 3.27\n",
      "49: Loss: 3.24\n",
      "50: Loss: 3.33\n",
      "51: Loss: 3.21\n",
      "52: Loss: 3.06\n",
      "53: Loss: 3.24\n",
      "54: Loss: 3.19\n",
      "55: Loss: 3.11\n",
      "56: Loss: 3.09\n",
      "57: Loss: 3.08\n",
      "58: Loss: 3.16\n",
      "59: Loss: 3.18\n",
      "60: Loss: 2.96\n",
      "61: Loss: 3.01\n",
      "62: Loss: 2.91\n",
      "63: Loss: 2.91\n",
      "64: Loss: 2.92\n",
      "65: Loss: 2.91\n",
      "66: Loss: 2.87\n",
      "67: Loss: 2.96\n",
      "68: Loss: 2.96\n",
      "69: Loss: 2.78\n",
      "70: Loss: 2.95\n",
      "71: Loss: 2.79\n",
      "72: Loss: 2.94\n",
      "73: Loss: 2.79\n",
      "74: Loss: 2.96\n",
      "75: Loss: 2.70\n",
      "76: Loss: 2.69\n",
      "77: Loss: 2.79\n",
      "78: Loss: 2.95\n",
      "79: Loss: 2.84\n",
      "80: Loss: 2.73\n",
      "81: Loss: 2.78\n",
      "82: Loss: 2.64\n",
      "83: Loss: 2.65\n",
      "84: Loss: 2.79\n",
      "85: Loss: 2.62\n",
      "86: Loss: 2.70\n",
      "87: Loss: 2.68\n",
      "88: Loss: 2.71\n",
      "89: Loss: 2.87\n",
      "90: Loss: 2.81\n",
      "91: Loss: 2.69\n",
      "92: Loss: 2.60\n",
      "93: Loss: 2.64\n",
      "94: Loss: 2.75\n",
      "95: Loss: 2.58\n",
      "96: Loss: 2.59\n",
      "97: Loss: 2.62\n",
      "98: Loss: 2.75\n",
      "99: Loss: 2.61\n",
      "101: Loss: 2.68\n",
      "102: Loss: 2.66\n",
      "103: Loss: 2.70\n",
      "104: Loss: 2.76\n",
      "105: Loss: 2.71\n",
      "106: Loss: 2.84\n",
      "107: Loss: 2.57\n",
      "108: Loss: 2.73\n",
      "109: Loss: 2.71\n",
      "110: Loss: 2.62\n",
      "111: Loss: 2.65\n",
      "112: Loss: 2.72\n",
      "113: Loss: 2.62\n",
      "114: Loss: 2.74\n",
      "115: Loss: 2.59\n",
      "116: Loss: 2.75\n",
      "117: Loss: 2.70\n",
      "118: Loss: 2.67\n",
      "119: Loss: 2.62\n",
      "120: Loss: 2.64\n",
      "121: Loss: 2.71\n",
      "122: Loss: 2.61\n",
      "123: Loss: 2.64\n",
      "124: Loss: 2.67\n",
      "125: Loss: 2.59\n",
      "126: Loss: 2.59\n",
      "127: Loss: 2.70\n",
      "128: Loss: 2.72\n",
      "129: Loss: 2.80\n",
      "130: Loss: 2.68\n",
      "131: Loss: 2.84\n",
      "132: Loss: 2.73\n",
      "133: Loss: 2.82\n",
      "134: Loss: 2.65\n",
      "135: Loss: 2.66\n",
      "136: Loss: 2.73\n",
      "137: Loss: 2.66\n",
      "138: Loss: 2.65\n",
      "139: Loss: 2.80\n",
      "140: Loss: 2.55\n",
      "141: Loss: 2.53\n",
      "142: Loss: 2.61\n",
      "143: Loss: 2.72\n",
      "144: Loss: 2.65\n",
      "145: Loss: 2.62\n",
      "146: Loss: 2.56\n",
      "147: Loss: 2.65\n",
      "148: Loss: 2.54\n",
      "149: Loss: 2.62\n",
      "150: Loss: 2.72\n",
      "151: Loss: 2.63\n",
      "152: Loss: 2.79\n",
      "153: Loss: 2.58\n",
      "154: Loss: 2.71\n",
      "155: Loss: 2.77\n",
      "156: Loss: 2.66\n",
      "157: Loss: 2.64\n",
      "158: Loss: 2.61\n",
      "159: Loss: 2.58\n",
      "160: Loss: 2.78\n",
      "161: Loss: 2.67\n",
      "162: Loss: 2.56\n",
      "163: Loss: 2.59\n",
      "164: Loss: 2.64\n",
      "165: Loss: 2.53\n",
      "166: Loss: 2.72\n",
      "167: Loss: 2.48\n",
      "168: Loss: 2.56\n",
      "169: Loss: 2.79\n",
      "170: Loss: 2.72\n",
      "171: Loss: 2.67\n",
      "172: Loss: 2.73\n",
      "173: Loss: 2.69\n",
      "174: Loss: 2.63\n",
      "175: Loss: 2.56\n",
      "176: Loss: 2.68\n",
      "177: Loss: 2.64\n",
      "178: Loss: 2.51\n",
      "179: Loss: 2.75\n",
      "180: Loss: 2.64\n",
      "181: Loss: 2.55\n",
      "182: Loss: 2.67\n",
      "183: Loss: 2.67\n",
      "184: Loss: 2.57\n",
      "185: Loss: 2.70\n",
      "186: Loss: 2.80\n",
      "187: Loss: 2.56\n",
      "188: Loss: 2.51\n",
      "189: Loss: 2.64\n",
      "190: Loss: 2.72\n",
      "191: Loss: 2.60\n",
      "192: Loss: 2.57\n",
      "193: Loss: 2.74\n",
      "194: Loss: 2.65\n",
      "195: Loss: 2.55\n",
      "196: Loss: 2.68\n",
      "197: Loss: 2.82\n",
      "198: Loss: 2.63\n",
      "199: Loss: 2.60\n",
      "201: Loss: 2.64\n",
      "202: Loss: 2.57\n",
      "203: Loss: 2.68\n",
      "204: Loss: 2.61\n",
      "205: Loss: 2.64\n",
      "206: Loss: 2.59\n",
      "207: Loss: 2.72\n",
      "208: Loss: 2.52\n",
      "209: Loss: 2.67\n",
      "210: Loss: 2.59\n",
      "211: Loss: 2.53\n",
      "212: Loss: 2.67\n",
      "213: Loss: 2.67\n",
      "214: Loss: 2.76\n",
      "215: Loss: 2.71\n",
      "216: Loss: 2.58\n",
      "217: Loss: 2.68\n",
      "218: Loss: 2.79\n",
      "219: Loss: 2.48\n",
      "220: Loss: 2.63\n",
      "221: Loss: 2.68\n",
      "222: Loss: 2.70\n",
      "223: Loss: 2.59\n",
      "224: Loss: 2.72\n",
      "225: Loss: 2.66\n",
      "226: Loss: 2.67\n",
      "227: Loss: 2.66\n",
      "228: Loss: 2.78\n",
      "229: Loss: 2.72\n",
      "230: Loss: 2.72\n",
      "231: Loss: 2.52\n",
      "232: Loss: 2.62\n",
      "233: Loss: 2.59\n",
      "234: Loss: 2.58\n",
      "235: Loss: 2.56\n",
      "236: Loss: 2.58\n",
      "237: Loss: 2.57\n",
      "238: Loss: 2.61\n",
      "239: Loss: 2.52\n",
      "240: Loss: 2.77\n",
      "241: Loss: 2.53\n",
      "242: Loss: 2.53\n",
      "243: Loss: 2.59\n",
      "244: Loss: 2.59\n",
      "245: Loss: 2.58\n",
      "246: Loss: 2.69\n",
      "247: Loss: 2.68\n",
      "248: Loss: 2.65\n",
      "249: Loss: 2.57\n",
      "250: Loss: 2.63\n",
      "251: Loss: 2.45\n",
      "252: Loss: 2.62\n",
      "253: Loss: 2.70\n",
      "254: Loss: 2.72\n",
      "255: Loss: 2.60\n",
      "256: Loss: 2.75\n",
      "257: Loss: 2.62\n",
      "258: Loss: 2.58\n",
      "259: Loss: 2.66\n",
      "260: Loss: 2.52\n",
      "261: Loss: 2.52\n",
      "262: Loss: 2.59\n",
      "263: Loss: 2.52\n",
      "264: Loss: 2.49\n",
      "265: Loss: 2.64\n",
      "266: Loss: 2.59\n",
      "267: Loss: 2.64\n",
      "268: Loss: 2.49\n",
      "269: Loss: 2.64\n",
      "270: Loss: 2.69\n",
      "271: Loss: 2.54\n",
      "272: Loss: 2.72\n",
      "273: Loss: 2.57\n",
      "274: Loss: 2.80\n",
      "275: Loss: 2.68\n",
      "276: Loss: 2.65\n",
      "277: Loss: 2.76\n",
      "278: Loss: 2.49\n",
      "279: Loss: 2.61\n",
      "280: Loss: 2.63\n",
      "281: Loss: 2.62\n",
      "282: Loss: 2.51\n",
      "283: Loss: 2.68\n",
      "284: Loss: 2.62\n",
      "285: Loss: 2.67\n",
      "286: Loss: 2.64\n",
      "287: Loss: 2.58\n",
      "288: Loss: 2.59\n",
      "289: Loss: 2.72\n",
      "290: Loss: 2.59\n",
      "291: Loss: 2.56\n",
      "292: Loss: 2.57\n",
      "293: Loss: 2.46\n",
      "294: Loss: 2.52\n",
      "295: Loss: 2.74\n",
      "296: Loss: 2.50\n",
      "297: Loss: 2.44\n",
      "298: Loss: 2.62\n",
      "299: Loss: 2.44\n",
      "301: Loss: 2.63\n",
      "302: Loss: 2.73\n",
      "303: Loss: 2.52\n",
      "304: Loss: 2.52\n",
      "305: Loss: 2.53\n",
      "306: Loss: 2.42\n",
      "307: Loss: 2.62\n",
      "308: Loss: 2.49\n",
      "309: Loss: 2.48\n",
      "310: Loss: 2.56\n",
      "311: Loss: 2.61\n",
      "312: Loss: 2.59\n",
      "313: Loss: 2.43\n",
      "314: Loss: 2.55\n",
      "315: Loss: 2.50\n",
      "316: Loss: 2.65\n",
      "317: Loss: 2.60\n",
      "318: Loss: 2.64\n",
      "319: Loss: 2.50\n",
      "320: Loss: 2.76\n",
      "321: Loss: 2.60\n",
      "322: Loss: 2.59\n",
      "323: Loss: 2.45\n",
      "324: Loss: 2.61\n",
      "325: Loss: 2.61\n",
      "326: Loss: 2.69\n",
      "327: Loss: 2.46\n",
      "328: Loss: 2.65\n",
      "329: Loss: 2.45\n",
      "330: Loss: 2.73\n",
      "331: Loss: 2.51\n",
      "332: Loss: 2.62\n",
      "333: Loss: 2.57\n",
      "334: Loss: 2.56\n",
      "335: Loss: 2.54\n",
      "336: Loss: 2.50\n",
      "337: Loss: 2.55\n",
      "338: Loss: 2.54\n",
      "339: Loss: 2.59\n",
      "340: Loss: 2.52\n",
      "341: Loss: 2.47\n",
      "342: Loss: 2.49\n",
      "343: Loss: 2.62\n",
      "344: Loss: 2.56\n",
      "345: Loss: 2.46\n",
      "346: Loss: 2.69\n",
      "347: Loss: 2.68\n",
      "348: Loss: 2.48\n",
      "349: Loss: 2.51\n",
      "350: Loss: 2.60\n",
      "351: Loss: 2.71\n",
      "352: Loss: 2.62\n",
      "353: Loss: 2.66\n",
      "354: Loss: 2.51\n",
      "355: Loss: 2.52\n",
      "356: Loss: 2.71\n",
      "357: Loss: 2.72\n",
      "358: Loss: 2.42\n",
      "359: Loss: 2.70\n",
      "360: Loss: 2.63\n",
      "361: Loss: 2.56\n",
      "362: Loss: 2.54\n",
      "363: Loss: 2.53\n",
      "364: Loss: 2.56\n",
      "365: Loss: 2.74\n",
      "366: Loss: 2.69\n",
      "367: Loss: 2.57\n",
      "368: Loss: 2.58\n",
      "369: Loss: 2.41\n",
      "370: Loss: 2.38\n",
      "371: Loss: 2.45\n",
      "372: Loss: 2.54\n",
      "373: Loss: 2.44\n",
      "374: Loss: 2.56\n",
      "375: Loss: 2.50\n",
      "376: Loss: 2.56\n",
      "377: Loss: 2.73\n",
      "378: Loss: 2.43\n",
      "379: Loss: 2.47\n",
      "380: Loss: 2.70\n",
      "381: Loss: 2.50\n",
      "382: Loss: 2.56\n",
      "383: Loss: 2.45\n",
      "384: Loss: 2.53\n",
      "385: Loss: 2.73\n",
      "386: Loss: 2.57\n",
      "387: Loss: 2.40\n",
      "388: Loss: 2.67\n",
      "389: Loss: 2.57\n",
      "390: Loss: 2.61\n",
      "391: Loss: 2.55\n",
      "392: Loss: 2.70\n",
      "393: Loss: 2.55\n",
      "394: Loss: 2.40\n",
      "395: Loss: 2.53\n",
      "396: Loss: 2.54\n",
      "397: Loss: 2.54\n",
      "398: Loss: 2.59\n",
      "399: Loss: 2.63\n",
      "401: Loss: 2.48\n",
      "402: Loss: 2.45\n",
      "403: Loss: 2.54\n",
      "404: Loss: 2.43\n",
      "405: Loss: 2.39\n",
      "406: Loss: 2.63\n",
      "407: Loss: 2.54\n",
      "408: Loss: 2.53\n",
      "409: Loss: 2.64\n",
      "410: Loss: 2.55\n",
      "411: Loss: 2.51\n",
      "412: Loss: 2.54\n",
      "413: Loss: 2.50\n",
      "414: Loss: 2.60\n",
      "415: Loss: 2.58\n",
      "416: Loss: 2.45\n",
      "417: Loss: 2.48\n",
      "418: Loss: 2.47\n",
      "419: Loss: 2.44\n",
      "420: Loss: 2.48\n",
      "421: Loss: 2.60\n",
      "422: Loss: 2.68\n",
      "423: Loss: 2.68\n",
      "424: Loss: 2.48\n",
      "425: Loss: 2.69\n",
      "426: Loss: 2.54\n",
      "427: Loss: 2.53\n",
      "428: Loss: 2.48\n",
      "429: Loss: 2.58\n",
      "430: Loss: 2.51\n",
      "431: Loss: 2.56\n",
      "432: Loss: 2.47\n",
      "433: Loss: 2.45\n",
      "434: Loss: 2.49\n",
      "435: Loss: 2.40\n",
      "436: Loss: 2.60\n",
      "437: Loss: 2.43\n",
      "438: Loss: 2.69\n",
      "439: Loss: 2.50\n",
      "440: Loss: 2.47\n",
      "441: Loss: 2.59\n",
      "442: Loss: 2.54\n",
      "443: Loss: 2.36\n",
      "444: Loss: 2.48\n",
      "445: Loss: 2.46\n",
      "446: Loss: 2.37\n",
      "447: Loss: 2.41\n",
      "448: Loss: 2.59\n",
      "449: Loss: 2.49\n",
      "450: Loss: 2.49\n",
      "451: Loss: 2.37\n",
      "452: Loss: 2.42\n",
      "453: Loss: 2.63\n",
      "454: Loss: 2.42\n",
      "455: Loss: 2.49\n",
      "456: Loss: 2.45\n",
      "457: Loss: 2.36\n",
      "458: Loss: 2.44\n",
      "459: Loss: 2.49\n",
      "460: Loss: 2.60\n",
      "461: Loss: 2.34\n",
      "462: Loss: 2.49\n",
      "463: Loss: 2.57\n",
      "464: Loss: 2.51\n",
      "465: Loss: 2.58\n",
      "466: Loss: 2.44\n",
      "467: Loss: 2.44\n",
      "468: Loss: 2.46\n",
      "469: Loss: 2.49\n",
      "470: Loss: 2.40\n",
      "471: Loss: 2.38\n",
      "472: Loss: 2.42\n",
      "473: Loss: 2.36\n",
      "474: Loss: 2.44\n",
      "475: Loss: 2.55\n",
      "476: Loss: 2.44\n",
      "477: Loss: 2.43\n",
      "478: Loss: 2.50\n",
      "479: Loss: 2.45\n",
      "480: Loss: 2.42\n",
      "481: Loss: 2.26\n",
      "482: Loss: 2.55\n",
      "483: Loss: 2.31\n",
      "484: Loss: 2.27\n",
      "485: Loss: 2.60\n",
      "486: Loss: 2.37\n",
      "487: Loss: 2.59\n",
      "488: Loss: 2.37\n",
      "489: Loss: 2.34\n",
      "490: Loss: 2.40\n",
      "491: Loss: 2.52\n",
      "492: Loss: 2.55\n",
      "493: Loss: 2.58\n",
      "494: Loss: 2.47\n",
      "495: Loss: 2.32\n",
      "496: Loss: 2.42\n",
      "497: Loss: 2.45\n",
      "498: Loss: 2.30\n",
      "499: Loss: 2.56\n",
      "501: Loss: 2.40\n",
      "502: Loss: 2.37\n",
      "503: Loss: 2.30\n",
      "504: Loss: 2.31\n",
      "505: Loss: 2.27\n",
      "506: Loss: 2.41\n",
      "507: Loss: 2.34\n",
      "508: Loss: 2.41\n",
      "509: Loss: 2.28\n",
      "510: Loss: 2.36\n",
      "511: Loss: 2.43\n",
      "512: Loss: 2.48\n",
      "513: Loss: 2.37\n",
      "514: Loss: 2.38\n",
      "515: Loss: 2.30\n",
      "516: Loss: 2.61\n",
      "517: Loss: 2.45\n",
      "518: Loss: 2.52\n",
      "519: Loss: 2.39\n",
      "520: Loss: 2.52\n",
      "521: Loss: 2.33\n",
      "522: Loss: 2.27\n",
      "523: Loss: 2.34\n",
      "524: Loss: 2.29\n",
      "525: Loss: 2.24\n",
      "526: Loss: 2.41\n",
      "527: Loss: 2.33\n",
      "528: Loss: 2.36\n",
      "529: Loss: 2.33\n",
      "530: Loss: 2.35\n",
      "531: Loss: 2.52\n",
      "532: Loss: 2.21\n",
      "533: Loss: 2.23\n",
      "534: Loss: 2.56\n",
      "535: Loss: 2.34\n",
      "536: Loss: 2.33\n",
      "537: Loss: 2.39\n",
      "538: Loss: 2.42\n",
      "539: Loss: 2.43\n",
      "540: Loss: 2.43\n",
      "541: Loss: 2.37\n",
      "542: Loss: 2.47\n",
      "543: Loss: 2.29\n",
      "544: Loss: 2.48\n",
      "545: Loss: 2.33\n",
      "546: Loss: 2.19\n",
      "547: Loss: 2.36\n",
      "548: Loss: 2.29\n",
      "549: Loss: 2.36\n",
      "550: Loss: 2.29\n",
      "551: Loss: 2.33\n",
      "552: Loss: 2.28\n",
      "553: Loss: 2.26\n",
      "554: Loss: 2.44\n",
      "555: Loss: 2.33\n",
      "556: Loss: 2.48\n",
      "557: Loss: 2.37\n",
      "558: Loss: 2.37\n",
      "559: Loss: 2.22\n",
      "560: Loss: 2.40\n",
      "561: Loss: 2.50\n",
      "562: Loss: 2.22\n",
      "563: Loss: 2.18\n",
      "564: Loss: 2.26\n",
      "565: Loss: 2.37\n",
      "566: Loss: 2.31\n",
      "567: Loss: 2.34\n",
      "568: Loss: 2.14\n",
      "569: Loss: 2.31\n",
      "570: Loss: 2.28\n",
      "571: Loss: 2.44\n",
      "572: Loss: 2.43\n",
      "573: Loss: 2.38\n",
      "574: Loss: 2.28\n",
      "575: Loss: 2.30\n",
      "576: Loss: 2.28\n",
      "577: Loss: 2.23\n",
      "578: Loss: 2.39\n",
      "579: Loss: 2.55\n",
      "580: Loss: 2.31\n",
      "581: Loss: 2.31\n",
      "582: Loss: 2.45\n",
      "583: Loss: 2.44\n",
      "584: Loss: 2.38\n",
      "585: Loss: 2.32\n",
      "586: Loss: 2.36\n",
      "587: Loss: 2.34\n",
      "588: Loss: 2.41\n",
      "589: Loss: 2.29\n",
      "590: Loss: 2.57\n",
      "591: Loss: 2.21\n",
      "592: Loss: 2.57\n",
      "593: Loss: 2.36\n",
      "594: Loss: 2.23\n",
      "595: Loss: 2.26\n",
      "596: Loss: 2.33\n",
      "597: Loss: 2.35\n",
      "598: Loss: 2.50\n",
      "599: Loss: 2.36\n",
      "601: Loss: 2.46\n",
      "602: Loss: 2.37\n",
      "603: Loss: 2.43\n",
      "604: Loss: 2.31\n",
      "605: Loss: 2.25\n",
      "606: Loss: 2.39\n",
      "607: Loss: 2.35\n",
      "608: Loss: 2.27\n",
      "609: Loss: 2.35\n",
      "610: Loss: 2.29\n",
      "611: Loss: 2.31\n",
      "612: Loss: 2.35\n",
      "613: Loss: 2.37\n",
      "614: Loss: 2.35\n",
      "615: Loss: 2.38\n",
      "616: Loss: 2.55\n",
      "617: Loss: 2.48\n",
      "618: Loss: 2.51\n",
      "619: Loss: 2.44\n",
      "620: Loss: 2.29\n",
      "621: Loss: 2.30\n",
      "622: Loss: 2.29\n",
      "623: Loss: 2.25\n",
      "624: Loss: 2.24\n",
      "625: Loss: 2.21\n",
      "626: Loss: 2.29\n",
      "627: Loss: 2.27\n",
      "628: Loss: 2.38\n",
      "629: Loss: 2.52\n",
      "630: Loss: 2.36\n",
      "631: Loss: 2.27\n",
      "632: Loss: 2.20\n",
      "633: Loss: 2.29\n",
      "634: Loss: 2.44\n",
      "635: Loss: 2.40\n",
      "636: Loss: 2.27\n",
      "637: Loss: 2.49\n",
      "638: Loss: 2.21\n",
      "639: Loss: 2.17\n",
      "640: Loss: 2.27\n",
      "641: Loss: 2.32\n",
      "642: Loss: 2.24\n",
      "643: Loss: 2.26\n",
      "644: Loss: 2.15\n",
      "645: Loss: 2.44\n",
      "646: Loss: 2.38\n",
      "647: Loss: 2.33\n",
      "648: Loss: 2.14\n",
      "649: Loss: 2.26\n",
      "650: Loss: 2.16\n",
      "651: Loss: 2.28\n",
      "652: Loss: 2.29\n",
      "653: Loss: 2.34\n",
      "654: Loss: 2.24\n",
      "655: Loss: 2.48\n",
      "656: Loss: 2.31\n",
      "657: Loss: 2.22\n",
      "658: Loss: 2.39\n",
      "659: Loss: 2.32\n",
      "660: Loss: 2.32\n",
      "661: Loss: 2.26\n",
      "662: Loss: 2.30\n",
      "663: Loss: 2.10\n",
      "664: Loss: 2.40\n",
      "665: Loss: 2.37\n",
      "666: Loss: 2.40\n",
      "667: Loss: 2.23\n",
      "668: Loss: 2.18\n",
      "669: Loss: 2.20\n",
      "670: Loss: 2.23\n",
      "671: Loss: 2.20\n",
      "672: Loss: 2.29\n",
      "673: Loss: 2.69\n",
      "674: Loss: 2.35\n",
      "675: Loss: 2.23\n",
      "676: Loss: 2.27\n",
      "677: Loss: 2.29\n",
      "678: Loss: 2.26\n",
      "679: Loss: 2.14\n",
      "680: Loss: 2.32\n",
      "681: Loss: 2.25\n",
      "682: Loss: 2.25\n",
      "683: Loss: 2.32\n",
      "684: Loss: 2.17\n",
      "685: Loss: 2.14\n",
      "686: Loss: 2.24\n",
      "687: Loss: 2.29\n",
      "688: Loss: 2.41\n",
      "689: Loss: 2.24\n",
      "690: Loss: 2.27\n",
      "691: Loss: 2.23\n",
      "692: Loss: 2.31\n",
      "693: Loss: 2.14\n",
      "694: Loss: 2.20\n",
      "695: Loss: 2.22\n",
      "696: Loss: 2.17\n",
      "697: Loss: 2.36\n",
      "698: Loss: 2.25\n",
      "699: Loss: 2.12\n",
      "701: Loss: 2.31\n",
      "702: Loss: 2.12\n",
      "703: Loss: 2.32\n",
      "704: Loss: 2.41\n",
      "705: Loss: 2.35\n",
      "706: Loss: 2.27\n",
      "707: Loss: 2.27\n",
      "708: Loss: 2.23\n",
      "709: Loss: 2.23\n",
      "710: Loss: 2.43\n",
      "711: Loss: 2.36\n",
      "712: Loss: 2.16\n",
      "713: Loss: 2.34\n",
      "714: Loss: 2.24\n",
      "715: Loss: 2.36\n",
      "716: Loss: 2.17\n",
      "717: Loss: 2.20\n",
      "718: Loss: 2.23\n",
      "719: Loss: 2.22\n",
      "720: Loss: 2.26\n",
      "721: Loss: 2.32\n",
      "722: Loss: 2.57\n",
      "723: Loss: 2.28\n",
      "724: Loss: 2.42\n",
      "725: Loss: 2.25\n",
      "726: Loss: 2.17\n",
      "727: Loss: 2.31\n",
      "728: Loss: 2.22\n",
      "729: Loss: 2.20\n",
      "730: Loss: 2.19\n",
      "731: Loss: 2.36\n",
      "732: Loss: 2.28\n",
      "733: Loss: 2.22\n",
      "734: Loss: 2.33\n",
      "735: Loss: 2.30\n",
      "736: Loss: 2.27\n",
      "737: Loss: 2.13\n",
      "738: Loss: 2.42\n",
      "739: Loss: 2.29\n",
      "740: Loss: 2.16\n",
      "741: Loss: 2.34\n",
      "742: Loss: 2.14\n",
      "743: Loss: 2.19\n",
      "744: Loss: 2.09\n",
      "745: Loss: 2.21\n",
      "746: Loss: 2.45\n",
      "747: Loss: 2.33\n",
      "748: Loss: 2.16\n",
      "749: Loss: 2.21\n",
      "750: Loss: 2.16\n",
      "751: Loss: 2.21\n",
      "752: Loss: 2.34\n",
      "753: Loss: 2.14\n",
      "754: Loss: 2.09\n",
      "755: Loss: 2.21\n",
      "756: Loss: 2.40\n",
      "757: Loss: 2.12\n",
      "758: Loss: 2.14\n",
      "759: Loss: 2.27\n",
      "760: Loss: 2.15\n",
      "761: Loss: 2.35\n",
      "762: Loss: 2.39\n",
      "763: Loss: 2.09\n",
      "764: Loss: 2.15\n",
      "765: Loss: 2.10\n",
      "766: Loss: 2.29\n",
      "767: Loss: 2.15\n",
      "768: Loss: 2.34\n",
      "769: Loss: 2.05\n",
      "770: Loss: 2.28\n",
      "771: Loss: 2.16\n",
      "772: Loss: 2.19\n",
      "773: Loss: 2.17\n",
      "774: Loss: 2.13\n",
      "775: Loss: 2.17\n",
      "776: Loss: 2.25\n",
      "777: Loss: 2.04\n",
      "778: Loss: 2.02\n",
      "779: Loss: 2.03\n",
      "780: Loss: 2.15\n",
      "781: Loss: 2.18\n",
      "782: Loss: 2.08\n",
      "783: Loss: 2.15\n",
      "784: Loss: 2.24\n",
      "785: Loss: 2.27\n",
      "786: Loss: 2.15\n",
      "787: Loss: 2.21\n",
      "788: Loss: 2.08\n",
      "789: Loss: 2.21\n",
      "790: Loss: 2.03\n",
      "791: Loss: 2.21\n",
      "792: Loss: 2.18\n",
      "793: Loss: 2.07\n",
      "794: Loss: 2.12\n",
      "795: Loss: 2.09\n",
      "796: Loss: 2.27\n",
      "797: Loss: 2.08\n",
      "798: Loss: 2.08\n",
      "799: Loss: 2.07\n",
      "801: Loss: 2.02\n",
      "802: Loss: 1.99\n",
      "803: Loss: 2.02\n",
      "804: Loss: 2.14\n",
      "805: Loss: 2.25\n",
      "806: Loss: 2.09\n",
      "807: Loss: 2.05\n",
      "808: Loss: 2.09\n",
      "809: Loss: 2.27\n",
      "810: Loss: 2.15\n",
      "811: Loss: 2.17\n",
      "812: Loss: 2.12\n",
      "813: Loss: 2.18\n",
      "814: Loss: 2.05\n",
      "815: Loss: 2.16\n",
      "816: Loss: 2.06\n",
      "817: Loss: 2.04\n",
      "818: Loss: 2.25\n",
      "819: Loss: 2.05\n",
      "820: Loss: 2.07\n",
      "821: Loss: 2.26\n",
      "822: Loss: 2.13\n",
      "823: Loss: 2.12\n",
      "824: Loss: 1.97\n",
      "825: Loss: 1.97\n",
      "826: Loss: 2.05\n",
      "827: Loss: 2.10\n",
      "828: Loss: 1.94\n",
      "829: Loss: 2.04\n",
      "830: Loss: 2.03\n",
      "831: Loss: 2.06\n",
      "832: Loss: 2.00\n",
      "833: Loss: 1.95\n",
      "834: Loss: 1.95\n",
      "835: Loss: 1.97\n",
      "836: Loss: 2.13\n",
      "837: Loss: 1.95\n",
      "838: Loss: 2.01\n",
      "839: Loss: 2.17\n",
      "840: Loss: 2.13\n",
      "841: Loss: 2.04\n",
      "842: Loss: 2.20\n",
      "843: Loss: 2.08\n",
      "844: Loss: 1.98\n",
      "845: Loss: 2.29\n",
      "846: Loss: 1.96\n",
      "847: Loss: 2.01\n",
      "848: Loss: 1.94\n",
      "849: Loss: 2.11\n",
      "850: Loss: 2.01\n",
      "851: Loss: 2.03\n",
      "852: Loss: 1.92\n",
      "853: Loss: 2.08\n",
      "854: Loss: 2.24\n",
      "855: Loss: 2.05\n",
      "856: Loss: 1.93\n",
      "857: Loss: 1.80\n",
      "858: Loss: 1.99\n",
      "859: Loss: 2.04\n",
      "860: Loss: 1.85\n",
      "861: Loss: 1.92\n",
      "862: Loss: 1.91\n",
      "863: Loss: 2.12\n",
      "864: Loss: 2.21\n",
      "865: Loss: 1.94\n",
      "866: Loss: 1.85\n",
      "867: Loss: 2.13\n",
      "868: Loss: 2.06\n",
      "869: Loss: 1.92\n",
      "870: Loss: 2.01\n",
      "871: Loss: 2.03\n",
      "872: Loss: 1.93\n",
      "873: Loss: 1.99\n",
      "874: Loss: 2.02\n",
      "875: Loss: 1.90\n",
      "876: Loss: 1.91\n",
      "877: Loss: 1.87\n",
      "878: Loss: 1.85\n",
      "879: Loss: 1.87\n",
      "880: Loss: 2.00\n",
      "881: Loss: 1.86\n",
      "882: Loss: 1.78\n",
      "883: Loss: 1.97\n",
      "884: Loss: 1.86\n",
      "885: Loss: 1.98\n",
      "886: Loss: 1.92\n",
      "887: Loss: 1.89\n",
      "888: Loss: 1.86\n",
      "889: Loss: 1.77\n",
      "890: Loss: 1.89\n",
      "891: Loss: 1.81\n",
      "892: Loss: 1.76\n",
      "893: Loss: 1.75\n",
      "894: Loss: 1.87\n",
      "895: Loss: 1.97\n",
      "896: Loss: 2.10\n",
      "897: Loss: 1.92\n",
      "898: Loss: 2.06\n",
      "899: Loss: 1.82\n",
      "901: Loss: 1.82\n",
      "902: Loss: 1.79\n",
      "903: Loss: 1.76\n",
      "904: Loss: 1.81\n",
      "905: Loss: 2.00\n",
      "906: Loss: 1.92\n",
      "907: Loss: 1.79\n",
      "908: Loss: 1.75\n",
      "909: Loss: 1.93\n",
      "910: Loss: 1.90\n",
      "911: Loss: 1.77\n",
      "912: Loss: 1.84\n",
      "913: Loss: 1.78\n",
      "914: Loss: 1.81\n",
      "915: Loss: 1.76\n",
      "916: Loss: 1.74\n",
      "917: Loss: 1.66\n",
      "918: Loss: 1.68\n",
      "919: Loss: 1.69\n",
      "920: Loss: 1.75\n",
      "921: Loss: 1.70\n",
      "922: Loss: 1.83\n",
      "923: Loss: 1.76\n",
      "924: Loss: 1.60\n",
      "925: Loss: 1.72\n",
      "926: Loss: 1.77\n",
      "927: Loss: 1.67\n",
      "928: Loss: 1.68\n",
      "929: Loss: 1.69\n",
      "930: Loss: 1.81\n",
      "931: Loss: 1.75\n",
      "932: Loss: 1.79\n",
      "933: Loss: 1.69\n",
      "934: Loss: 1.59\n",
      "935: Loss: 1.83\n",
      "936: Loss: 1.78\n",
      "937: Loss: 1.73\n",
      "938: Loss: 1.58\n",
      "939: Loss: 1.65\n",
      "940: Loss: 1.74\n",
      "941: Loss: 1.68\n",
      "942: Loss: 1.84\n",
      "943: Loss: 1.58\n",
      "944: Loss: 1.61\n",
      "945: Loss: 1.80\n",
      "946: Loss: 1.61\n",
      "947: Loss: 1.68\n",
      "948: Loss: 1.70\n",
      "949: Loss: 1.53\n",
      "950: Loss: 1.62\n",
      "951: Loss: 1.67\n",
      "952: Loss: 1.60\n",
      "953: Loss: 1.62\n",
      "954: Loss: 1.48\n",
      "955: Loss: 1.54\n",
      "956: Loss: 1.50\n",
      "957: Loss: 1.58\n",
      "958: Loss: 1.81\n",
      "959: Loss: 1.61\n",
      "960: Loss: 1.80\n",
      "961: Loss: 1.85\n",
      "962: Loss: 1.44\n",
      "963: Loss: 1.71\n",
      "964: Loss: 1.80\n",
      "965: Loss: 1.50\n",
      "966: Loss: 1.59\n",
      "967: Loss: 1.62\n",
      "968: Loss: 1.81\n",
      "969: Loss: 1.62\n",
      "970: Loss: 1.45\n",
      "971: Loss: 1.51\n",
      "972: Loss: 1.57\n",
      "973: Loss: 1.68\n",
      "974: Loss: 1.66\n",
      "975: Loss: 1.64\n",
      "976: Loss: 1.56\n",
      "977: Loss: 1.43\n",
      "978: Loss: 1.74\n",
      "979: Loss: 1.57\n",
      "980: Loss: 1.50\n",
      "981: Loss: 1.59\n",
      "982: Loss: 1.59\n",
      "983: Loss: 1.49\n",
      "984: Loss: 1.68\n",
      "985: Loss: 1.50\n",
      "986: Loss: 1.55\n",
      "987: Loss: 1.85\n",
      "988: Loss: 1.61\n",
      "989: Loss: 1.53\n",
      "990: Loss: 1.79\n",
      "991: Loss: 1.72\n",
      "992: Loss: 1.50\n",
      "993: Loss: 1.54\n",
      "994: Loss: 1.66\n",
      "995: Loss: 1.55\n",
      "996: Loss: 1.51\n",
      "997: Loss: 1.73\n",
      "998: Loss: 1.46\n",
      "999: Loss: 1.77\n",
      "1001: Loss: 1.69\n",
      "1002: Loss: 1.74\n",
      "1003: Loss: 1.51\n",
      "1004: Loss: 1.56\n",
      "1005: Loss: 1.40\n",
      "1006: Loss: 1.74\n",
      "1007: Loss: 1.55\n",
      "1008: Loss: 1.58\n",
      "1009: Loss: 1.64\n",
      "1010: Loss: 1.63\n",
      "1011: Loss: 1.65\n",
      "1012: Loss: 1.56\n",
      "1013: Loss: 1.56\n",
      "1014: Loss: 1.53\n",
      "1015: Loss: 1.65\n",
      "1016: Loss: 1.53\n",
      "1017: Loss: 1.44\n",
      "1018: Loss: 1.40\n",
      "1019: Loss: 1.48\n",
      "1020: Loss: 1.39\n",
      "1021: Loss: 1.60\n",
      "1022: Loss: 1.43\n",
      "1023: Loss: 1.58\n",
      "1024: Loss: 1.74\n",
      "1025: Loss: 1.44\n",
      "1026: Loss: 1.39\n",
      "1027: Loss: 1.51\n",
      "1028: Loss: 1.59\n",
      "1029: Loss: 1.44\n",
      "1030: Loss: 1.46\n",
      "1031: Loss: 1.66\n",
      "1032: Loss: 1.50\n",
      "1033: Loss: 1.40\n",
      "1034: Loss: 1.70\n",
      "1035: Loss: 1.47\n",
      "1036: Loss: 1.64\n",
      "1037: Loss: 1.43\n",
      "1038: Loss: 1.36\n",
      "1039: Loss: 1.33\n",
      "1040: Loss: 1.85\n",
      "1041: Loss: 1.37\n",
      "1042: Loss: 1.31\n",
      "1043: Loss: 1.25\n",
      "1044: Loss: 1.39\n",
      "1045: Loss: 1.39\n",
      "1046: Loss: 1.38\n",
      "1047: Loss: 1.43\n",
      "1048: Loss: 1.33\n",
      "1049: Loss: 1.67\n",
      "1050: Loss: 1.35\n",
      "1051: Loss: 1.33\n",
      "1052: Loss: 1.54\n",
      "1053: Loss: 1.44\n",
      "1054: Loss: 1.55\n",
      "1055: Loss: 1.49\n",
      "1056: Loss: 1.51\n",
      "1057: Loss: 1.63\n",
      "1058: Loss: 1.31\n",
      "1059: Loss: 1.36\n",
      "1060: Loss: 1.50\n",
      "1061: Loss: 1.55\n",
      "1062: Loss: 1.34\n",
      "1063: Loss: 1.50\n",
      "1064: Loss: 1.44\n",
      "1065: Loss: 1.68\n",
      "1066: Loss: 1.42\n",
      "1067: Loss: 1.39\n",
      "1068: Loss: 1.47\n",
      "1069: Loss: 1.41\n",
      "1070: Loss: 1.49\n",
      "1071: Loss: 1.23\n",
      "1072: Loss: 1.45\n",
      "1073: Loss: 1.56\n",
      "1074: Loss: 1.48\n",
      "1075: Loss: 1.58\n",
      "1076: Loss: 1.58\n",
      "1077: Loss: 1.56\n",
      "1078: Loss: 1.34\n",
      "1079: Loss: 1.42\n",
      "1080: Loss: 1.56\n",
      "1081: Loss: 1.70\n",
      "1082: Loss: 1.51\n",
      "1083: Loss: 1.40\n",
      "1084: Loss: 1.41\n",
      "1085: Loss: 1.50\n",
      "1086: Loss: 1.54\n",
      "1087: Loss: 1.54\n",
      "1088: Loss: 1.42\n",
      "1089: Loss: 1.39\n",
      "1090: Loss: 1.38\n",
      "1091: Loss: 1.51\n",
      "1092: Loss: 1.53\n",
      "1093: Loss: 1.37\n",
      "1094: Loss: 1.33\n",
      "1095: Loss: 1.31\n",
      "1096: Loss: 1.35\n",
      "1097: Loss: 1.35\n",
      "1098: Loss: 1.41\n",
      "1099: Loss: 1.31\n",
      "1101: Loss: 1.47\n",
      "1102: Loss: 1.36\n",
      "1103: Loss: 1.18\n",
      "1104: Loss: 1.27\n",
      "1105: Loss: 1.38\n",
      "1106: Loss: 1.29\n",
      "1107: Loss: 1.28\n",
      "1108: Loss: 1.33\n",
      "1109: Loss: 1.51\n",
      "1110: Loss: 1.38\n",
      "1111: Loss: 1.22\n",
      "1112: Loss: 1.31\n",
      "1113: Loss: 1.33\n",
      "1114: Loss: 1.31\n",
      "1115: Loss: 1.42\n",
      "1116: Loss: 1.35\n",
      "1117: Loss: 1.51\n",
      "1118: Loss: 1.15\n",
      "1119: Loss: 1.26\n",
      "1120: Loss: 1.23\n",
      "1121: Loss: 1.19\n",
      "1122: Loss: 1.37\n",
      "1123: Loss: 1.41\n",
      "1124: Loss: 1.54\n",
      "1125: Loss: 1.53\n",
      "1126: Loss: 1.34\n",
      "1127: Loss: 1.29\n",
      "1128: Loss: 1.38\n",
      "1129: Loss: 1.40\n",
      "1130: Loss: 1.41\n",
      "1131: Loss: 1.39\n",
      "1132: Loss: 1.52\n",
      "1133: Loss: 1.46\n",
      "1134: Loss: 1.32\n",
      "1135: Loss: 1.35\n",
      "1136: Loss: 1.55\n",
      "1137: Loss: 1.79\n",
      "1138: Loss: 1.50\n",
      "1139: Loss: 1.31\n",
      "1140: Loss: 1.77\n",
      "1141: Loss: 1.47\n",
      "1142: Loss: 1.47\n",
      "1143: Loss: 1.60\n",
      "1144: Loss: 1.58\n",
      "1145: Loss: 1.50\n",
      "1146: Loss: 1.72\n",
      "1147: Loss: 1.62\n",
      "1148: Loss: 1.56\n",
      "1149: Loss: 1.66\n",
      "1150: Loss: 1.35\n",
      "1151: Loss: 1.46\n",
      "1152: Loss: 1.58\n",
      "1153: Loss: 1.51\n",
      "1154: Loss: 1.40\n",
      "1155: Loss: 1.32\n",
      "1156: Loss: 1.61\n",
      "1157: Loss: 1.34\n",
      "1158: Loss: 1.42\n",
      "1159: Loss: 1.35\n",
      "1160: Loss: 1.26\n",
      "1161: Loss: 1.49\n",
      "1162: Loss: 1.43\n",
      "1163: Loss: 1.64\n",
      "1164: Loss: 1.41\n",
      "1165: Loss: 1.39\n",
      "1166: Loss: 1.37\n",
      "1167: Loss: 1.32\n",
      "1168: Loss: 1.41\n",
      "1169: Loss: 1.28\n",
      "1170: Loss: 1.34\n",
      "1171: Loss: 1.26\n",
      "1172: Loss: 1.58\n",
      "1173: Loss: 1.37\n",
      "1174: Loss: 1.38\n",
      "1175: Loss: 1.36\n",
      "1176: Loss: 1.31\n",
      "1177: Loss: 1.30\n",
      "1178: Loss: 1.29\n",
      "1179: Loss: 1.31\n",
      "1180: Loss: 1.55\n",
      "1181: Loss: 1.33\n",
      "1182: Loss: 1.09\n",
      "1183: Loss: 1.33\n",
      "1184: Loss: 1.32\n",
      "1185: Loss: 1.19\n",
      "1186: Loss: 1.18\n",
      "1187: Loss: 1.39\n",
      "1188: Loss: 1.18\n",
      "1189: Loss: 1.13\n",
      "1190: Loss: 1.15\n",
      "1191: Loss: 1.15\n",
      "1192: Loss: 1.18\n",
      "1193: Loss: 1.17\n",
      "1194: Loss: 1.15\n",
      "1195: Loss: 1.30\n",
      "1196: Loss: 1.25\n",
      "1197: Loss: 1.33\n",
      "1198: Loss: 1.35\n",
      "1199: Loss: 1.11\n",
      "1201: Loss: 1.13\n",
      "1202: Loss: 1.30\n",
      "1203: Loss: 1.19\n",
      "1204: Loss: 1.12\n",
      "1205: Loss: 1.23\n",
      "1206: Loss: 1.17\n",
      "1207: Loss: 1.29\n",
      "1208: Loss: 1.17\n",
      "1209: Loss: 1.23\n",
      "1210: Loss: 1.17\n",
      "1211: Loss: 1.33\n",
      "1212: Loss: 1.42\n",
      "1213: Loss: 1.28\n",
      "1214: Loss: 1.39\n",
      "1215: Loss: 1.31\n",
      "1216: Loss: 1.20\n",
      "1217: Loss: 1.35\n",
      "1218: Loss: 1.18\n",
      "1219: Loss: 1.10\n",
      "1220: Loss: 1.20\n",
      "1221: Loss: 1.22\n",
      "1222: Loss: 1.15\n",
      "1223: Loss: 1.17\n",
      "1224: Loss: 1.26\n",
      "1225: Loss: 1.28\n",
      "1226: Loss: 1.11\n",
      "1227: Loss: 1.11\n",
      "1228: Loss: 1.33\n",
      "1229: Loss: 1.21\n",
      "1230: Loss: 1.17\n",
      "1231: Loss: 1.14\n",
      "1232: Loss: 1.08\n",
      "1233: Loss: 1.21\n",
      "1234: Loss: 1.29\n",
      "1235: Loss: 1.22\n",
      "1236: Loss: 1.09\n",
      "1237: Loss: 1.44\n",
      "1238: Loss: 1.24\n",
      "1239: Loss: 1.32\n",
      "1240: Loss: 1.15\n",
      "1241: Loss: 1.35\n",
      "1242: Loss: 1.33\n",
      "1243: Loss: 1.17\n",
      "1244: Loss: 1.10\n",
      "1245: Loss: 1.09\n",
      "1246: Loss: 1.04\n",
      "1247: Loss: 1.09\n",
      "1248: Loss: 1.10\n",
      "1249: Loss: 1.01\n",
      "1250: Loss: 1.16\n",
      "1251: Loss: 1.43\n",
      "1252: Loss: 0.95\n",
      "1253: Loss: 1.10\n",
      "1254: Loss: 1.18\n",
      "1255: Loss: 1.19\n",
      "1256: Loss: 1.01\n",
      "1257: Loss: 1.23\n",
      "1258: Loss: 1.20\n",
      "1259: Loss: 1.38\n",
      "1260: Loss: 1.04\n",
      "1261: Loss: 1.10\n",
      "1262: Loss: 1.14\n",
      "1263: Loss: 1.21\n",
      "1264: Loss: 1.06\n",
      "1265: Loss: 1.32\n",
      "1266: Loss: 0.99\n",
      "1267: Loss: 1.18\n",
      "1268: Loss: 1.05\n",
      "1269: Loss: 1.15\n",
      "1270: Loss: 1.24\n",
      "1271: Loss: 1.09\n",
      "1272: Loss: 1.27\n",
      "1273: Loss: 1.06\n",
      "1274: Loss: 1.15\n",
      "1275: Loss: 1.05\n",
      "1276: Loss: 1.08\n",
      "1277: Loss: 1.03\n",
      "1278: Loss: 0.93\n",
      "1279: Loss: 1.08\n",
      "1280: Loss: 1.13\n",
      "1281: Loss: 1.36\n",
      "1282: Loss: 1.07\n",
      "1283: Loss: 0.92\n",
      "1284: Loss: 1.08\n",
      "1285: Loss: 1.04\n",
      "1286: Loss: 0.94\n",
      "1287: Loss: 1.15\n",
      "1288: Loss: 1.10\n",
      "1289: Loss: 0.95\n",
      "1290: Loss: 1.09\n",
      "1291: Loss: 1.00\n",
      "1292: Loss: 1.12\n",
      "1293: Loss: 0.89\n",
      "1294: Loss: 1.03\n",
      "1295: Loss: 1.21\n",
      "1296: Loss: 1.02\n",
      "1297: Loss: 1.07\n",
      "1298: Loss: 0.94\n",
      "1299: Loss: 1.03\n",
      "1301: Loss: 1.03\n",
      "1302: Loss: 1.03\n",
      "1303: Loss: 0.82\n",
      "1304: Loss: 1.17\n",
      "1305: Loss: 1.19\n",
      "1306: Loss: 1.03\n",
      "1307: Loss: 0.92\n",
      "1308: Loss: 0.96\n",
      "1309: Loss: 0.97\n",
      "1310: Loss: 1.24\n",
      "1311: Loss: 0.98\n",
      "1312: Loss: 0.94\n",
      "1313: Loss: 0.98\n",
      "1314: Loss: 0.93\n",
      "1315: Loss: 1.01\n",
      "1316: Loss: 1.13\n",
      "1317: Loss: 0.95\n",
      "1318: Loss: 1.06\n",
      "1319: Loss: 0.97\n",
      "1320: Loss: 1.17\n",
      "1321: Loss: 1.23\n",
      "1322: Loss: 1.19\n",
      "1323: Loss: 1.54\n",
      "1324: Loss: 1.07\n",
      "1325: Loss: 1.11\n",
      "1326: Loss: 1.08\n",
      "1327: Loss: 0.93\n",
      "1328: Loss: 1.12\n",
      "1329: Loss: 1.11\n",
      "1330: Loss: 0.93\n",
      "1331: Loss: 0.99\n",
      "1332: Loss: 0.90\n",
      "1333: Loss: 1.10\n",
      "1334: Loss: 1.03\n",
      "1335: Loss: 1.07\n",
      "1336: Loss: 1.05\n",
      "1337: Loss: 1.17\n",
      "1338: Loss: 0.99\n",
      "1339: Loss: 0.93\n",
      "1340: Loss: 1.09\n",
      "1341: Loss: 0.95\n",
      "1342: Loss: 1.16\n",
      "1343: Loss: 1.08\n",
      "1344: Loss: 1.06\n",
      "1345: Loss: 1.16\n",
      "1346: Loss: 0.93\n",
      "1347: Loss: 0.95\n",
      "1348: Loss: 0.85\n",
      "1349: Loss: 0.87\n",
      "1350: Loss: 0.94\n",
      "1351: Loss: 0.96\n",
      "1352: Loss: 1.03\n",
      "1353: Loss: 0.93\n",
      "1354: Loss: 1.16\n",
      "1355: Loss: 0.86\n",
      "1356: Loss: 1.19\n",
      "1357: Loss: 0.84\n",
      "1358: Loss: 0.88\n",
      "1359: Loss: 0.85\n",
      "1360: Loss: 0.82\n",
      "1361: Loss: 0.90\n",
      "1362: Loss: 0.99\n",
      "1363: Loss: 1.06\n",
      "1364: Loss: 0.93\n",
      "1365: Loss: 0.89\n",
      "1366: Loss: 0.86\n",
      "1367: Loss: 0.78\n",
      "1368: Loss: 0.75\n",
      "1369: Loss: 0.93\n",
      "1370: Loss: 0.86\n",
      "1371: Loss: 0.86\n",
      "1372: Loss: 0.82\n",
      "1373: Loss: 0.88\n",
      "1374: Loss: 0.88\n",
      "1375: Loss: 0.95\n",
      "1376: Loss: 0.74\n",
      "1377: Loss: 0.90\n",
      "1378: Loss: 0.97\n",
      "1379: Loss: 1.02\n",
      "1380: Loss: 0.74\n",
      "1381: Loss: 0.92\n",
      "1382: Loss: 0.89\n",
      "1383: Loss: 1.08\n",
      "1384: Loss: 1.06\n",
      "1385: Loss: 0.77\n",
      "1386: Loss: 0.89\n",
      "1387: Loss: 1.07\n",
      "1388: Loss: 1.05\n",
      "1389: Loss: 0.97\n",
      "1390: Loss: 0.73\n",
      "1391: Loss: 1.03\n",
      "1392: Loss: 0.77\n",
      "1393: Loss: 1.13\n",
      "1394: Loss: 1.01\n",
      "1395: Loss: 0.82\n",
      "1396: Loss: 0.84\n",
      "1397: Loss: 0.86\n",
      "1398: Loss: 0.77\n",
      "1399: Loss: 0.92\n",
      "1401: Loss: 0.97\n",
      "1402: Loss: 0.89\n",
      "1403: Loss: 0.79\n",
      "1404: Loss: 0.80\n",
      "1405: Loss: 0.67\n",
      "1406: Loss: 0.78\n",
      "1407: Loss: 0.83\n",
      "1408: Loss: 0.80\n",
      "1409: Loss: 0.82\n",
      "1410: Loss: 0.74\n",
      "1411: Loss: 0.63\n",
      "1412: Loss: 0.86\n",
      "1413: Loss: 0.84\n",
      "1414: Loss: 0.66\n",
      "1415: Loss: 0.90\n",
      "1416: Loss: 1.13\n",
      "1417: Loss: 0.70\n",
      "1418: Loss: 0.78\n",
      "1419: Loss: 0.76\n",
      "1420: Loss: 0.97\n",
      "1421: Loss: 0.76\n",
      "1422: Loss: 0.86\n",
      "1423: Loss: 0.78\n",
      "1424: Loss: 0.88\n",
      "1425: Loss: 0.76\n",
      "1426: Loss: 0.73\n",
      "1427: Loss: 0.84\n",
      "1428: Loss: 0.76\n",
      "1429: Loss: 0.71\n",
      "1430: Loss: 0.78\n",
      "1431: Loss: 0.87\n",
      "1432: Loss: 0.83\n",
      "1433: Loss: 0.78\n",
      "1434: Loss: 0.72\n",
      "1435: Loss: 0.66\n",
      "1436: Loss: 0.82\n",
      "1437: Loss: 0.64\n",
      "1438: Loss: 0.68\n",
      "1439: Loss: 0.86\n",
      "1440: Loss: 0.83\n",
      "1441: Loss: 0.71\n",
      "1442: Loss: 0.84\n",
      "1443: Loss: 0.65\n",
      "1444: Loss: 0.74\n",
      "1445: Loss: 0.68\n",
      "1446: Loss: 0.73\n",
      "1447: Loss: 0.75\n",
      "1448: Loss: 0.85\n",
      "1449: Loss: 0.84\n",
      "1450: Loss: 0.77\n",
      "1451: Loss: 0.86\n",
      "1452: Loss: 0.83\n",
      "1453: Loss: 0.78\n",
      "1454: Loss: 0.68\n",
      "1455: Loss: 0.76\n",
      "1456: Loss: 0.64\n",
      "1457: Loss: 0.69\n",
      "1458: Loss: 0.67\n",
      "1459: Loss: 0.63\n",
      "1460: Loss: 0.60\n",
      "1461: Loss: 0.77\n",
      "1462: Loss: 0.63\n",
      "1463: Loss: 0.78\n",
      "1464: Loss: 0.66\n",
      "1465: Loss: 0.68\n",
      "1466: Loss: 0.71\n",
      "1467: Loss: 0.68\n",
      "1468: Loss: 0.61\n",
      "1469: Loss: 0.56\n",
      "1470: Loss: 0.82\n",
      "1471: Loss: 0.77\n",
      "1472: Loss: 0.76\n",
      "1473: Loss: 0.60\n",
      "1474: Loss: 0.64\n",
      "1475: Loss: 0.47\n",
      "1476: Loss: 0.52\n",
      "1477: Loss: 0.64\n",
      "1478: Loss: 0.62\n",
      "1479: Loss: 0.70\n",
      "1480: Loss: 0.68\n",
      "1481: Loss: 0.66\n",
      "1482: Loss: 0.66\n",
      "1483: Loss: 0.65\n",
      "1484: Loss: 0.63\n",
      "1485: Loss: 0.60\n",
      "1486: Loss: 0.70\n",
      "1487: Loss: 0.62\n",
      "1488: Loss: 0.70\n",
      "1489: Loss: 0.60\n",
      "1490: Loss: 0.81\n",
      "1491: Loss: 0.73\n",
      "1492: Loss: 0.67\n",
      "1493: Loss: 0.64\n",
      "1494: Loss: 0.55\n",
      "1495: Loss: 0.77\n",
      "1496: Loss: 0.74\n",
      "1497: Loss: 0.62\n",
      "1498: Loss: 0.61\n",
      "1499: Loss: 0.54\n",
      "1501: Loss: 0.67\n",
      "1502: Loss: 0.55\n",
      "1503: Loss: 0.61\n",
      "1504: Loss: 0.64\n",
      "1505: Loss: 0.74\n",
      "1506: Loss: 0.59\n",
      "1507: Loss: 0.79\n",
      "1508: Loss: 0.82\n",
      "1509: Loss: 0.67\n",
      "1510: Loss: 0.68\n",
      "1511: Loss: 0.59\n",
      "1512: Loss: 0.84\n",
      "1513: Loss: 0.71\n",
      "1514: Loss: 0.69\n",
      "1515: Loss: 0.75\n",
      "1516: Loss: 0.61\n",
      "1517: Loss: 0.63\n",
      "1518: Loss: 0.62\n",
      "1519: Loss: 0.58\n",
      "1520: Loss: 0.62\n",
      "1521: Loss: 0.63\n",
      "1522: Loss: 0.58\n",
      "1523: Loss: 0.73\n",
      "1524: Loss: 0.62\n",
      "1525: Loss: 0.68\n",
      "1526: Loss: 0.54\n",
      "1527: Loss: 0.66\n",
      "1528: Loss: 0.52\n",
      "1529: Loss: 0.73\n",
      "1530: Loss: 0.67\n",
      "1531: Loss: 0.44\n",
      "1532: Loss: 0.59\n",
      "1533: Loss: 0.60\n",
      "1534: Loss: 0.60\n",
      "1535: Loss: 0.53\n",
      "1536: Loss: 0.83\n",
      "1537: Loss: 0.59\n",
      "1538: Loss: 0.66\n",
      "1539: Loss: 0.69\n",
      "1540: Loss: 0.77\n",
      "1541: Loss: 0.68\n",
      "1542: Loss: 0.57\n",
      "1543: Loss: 0.63\n",
      "1544: Loss: 0.64\n",
      "1545: Loss: 0.63\n",
      "1546: Loss: 0.63\n",
      "1547: Loss: 0.66\n",
      "1548: Loss: 0.63\n",
      "1549: Loss: 0.65\n",
      "1550: Loss: 0.58\n",
      "1551: Loss: 0.68\n",
      "1552: Loss: 0.77\n",
      "1553: Loss: 0.68\n",
      "1554: Loss: 0.64\n",
      "1555: Loss: 0.59\n",
      "1556: Loss: 0.62\n",
      "1557: Loss: 0.62\n",
      "1558: Loss: 0.55\n",
      "1559: Loss: 0.61\n",
      "1560: Loss: 0.66\n",
      "1561: Loss: 0.57\n",
      "1562: Loss: 0.62\n",
      "1563: Loss: 0.60\n",
      "1564: Loss: 0.90\n",
      "1565: Loss: 0.64\n",
      "1566: Loss: 0.74\n",
      "1567: Loss: 0.78\n",
      "1568: Loss: 0.69\n",
      "1569: Loss: 0.65\n",
      "1570: Loss: 0.74\n",
      "1571: Loss: 0.74\n",
      "1572: Loss: 0.75\n",
      "1573: Loss: 0.79\n",
      "1574: Loss: 0.75\n",
      "1575: Loss: 0.68\n",
      "1576: Loss: 0.70\n",
      "1577: Loss: 0.86\n",
      "1578: Loss: 0.71\n",
      "1579: Loss: 0.71\n",
      "1580: Loss: 0.64\n",
      "1581: Loss: 0.62\n",
      "1582: Loss: 0.76\n",
      "1583: Loss: 0.54\n",
      "1584: Loss: 0.52\n",
      "1585: Loss: 0.75\n",
      "1586: Loss: 0.78\n",
      "1587: Loss: 0.55\n",
      "1588: Loss: 0.61\n",
      "1589: Loss: 0.72\n",
      "1590: Loss: 0.73\n",
      "1591: Loss: 0.58\n",
      "1592: Loss: 0.58\n",
      "1593: Loss: 0.60\n",
      "1594: Loss: 0.46\n",
      "1595: Loss: 0.49\n",
      "1596: Loss: 0.56\n",
      "1597: Loss: 0.62\n",
      "1598: Loss: 0.58\n",
      "1599: Loss: 0.51\n",
      "1601: Loss: 0.64\n",
      "1602: Loss: 0.45\n",
      "1603: Loss: 0.57\n",
      "1604: Loss: 0.46\n",
      "1605: Loss: 0.60\n",
      "1606: Loss: 0.61\n",
      "1607: Loss: 0.60\n",
      "1608: Loss: 0.63\n",
      "1609: Loss: 0.64\n",
      "1610: Loss: 0.51\n",
      "1611: Loss: 0.58\n",
      "1612: Loss: 0.75\n",
      "1613: Loss: 0.43\n",
      "1614: Loss: 0.49\n",
      "1615: Loss: 0.51\n",
      "1616: Loss: 0.46\n",
      "1617: Loss: 0.50\n",
      "1618: Loss: 0.56\n",
      "1619: Loss: 0.56\n",
      "1620: Loss: 0.47\n",
      "1621: Loss: 0.67\n",
      "1622: Loss: 0.59\n",
      "1623: Loss: 0.51\n",
      "1624: Loss: 0.40\n",
      "1625: Loss: 0.50\n",
      "1626: Loss: 0.56\n",
      "1627: Loss: 0.47\n",
      "1628: Loss: 0.53\n",
      "1629: Loss: 0.41\n",
      "1630: Loss: 0.51\n",
      "1631: Loss: 0.58\n",
      "1632: Loss: 0.55\n",
      "1633: Loss: 0.48\n",
      "1634: Loss: 0.73\n",
      "1635: Loss: 0.46\n",
      "1636: Loss: 0.54\n",
      "1637: Loss: 0.58\n",
      "1638: Loss: 0.47\n",
      "1639: Loss: 0.47\n",
      "1640: Loss: 0.51\n",
      "1641: Loss: 0.55\n",
      "1642: Loss: 0.50\n",
      "1643: Loss: 0.55\n",
      "1644: Loss: 0.55\n",
      "1645: Loss: 0.47\n",
      "1646: Loss: 0.34\n",
      "1647: Loss: 0.41\n",
      "1648: Loss: 0.58\n",
      "1649: Loss: 0.47\n",
      "1650: Loss: 0.40\n",
      "1651: Loss: 0.46\n",
      "1652: Loss: 0.59\n",
      "1653: Loss: 0.51\n",
      "1654: Loss: 0.47\n",
      "1655: Loss: 0.59\n",
      "1656: Loss: 0.51\n",
      "1657: Loss: 0.64\n",
      "1658: Loss: 0.38\n",
      "1659: Loss: 0.52\n",
      "1660: Loss: 0.51\n",
      "1661: Loss: 0.42\n",
      "1662: Loss: 0.44\n",
      "1663: Loss: 0.50\n",
      "1664: Loss: 0.74\n",
      "1665: Loss: 0.58\n",
      "1666: Loss: 0.37\n",
      "1667: Loss: 0.54\n",
      "1668: Loss: 0.56\n",
      "1669: Loss: 0.51\n",
      "1670: Loss: 0.44\n",
      "1671: Loss: 0.59\n",
      "1672: Loss: 0.51\n",
      "1673: Loss: 0.48\n",
      "1674: Loss: 0.50\n",
      "1675: Loss: 0.44\n",
      "1676: Loss: 0.56\n",
      "1677: Loss: 0.50\n",
      "1678: Loss: 0.47\n",
      "1679: Loss: 0.41\n",
      "1680: Loss: 0.56\n",
      "1681: Loss: 0.49\n",
      "1682: Loss: 0.58\n",
      "1683: Loss: 0.68\n",
      "1684: Loss: 0.50\n",
      "1685: Loss: 0.62\n",
      "1686: Loss: 0.59\n",
      "1687: Loss: 0.57\n",
      "1688: Loss: 0.51\n",
      "1689: Loss: 0.44\n",
      "1690: Loss: 0.95\n",
      "1691: Loss: 0.64\n",
      "1692: Loss: 0.81\n",
      "1693: Loss: 0.53\n",
      "1694: Loss: 0.74\n",
      "1695: Loss: 0.57\n",
      "1696: Loss: 0.42\n",
      "1697: Loss: 0.52\n",
      "1698: Loss: 0.63\n",
      "1699: Loss: 0.56\n",
      "1701: Loss: 0.59\n",
      "1702: Loss: 0.63\n",
      "1703: Loss: 0.55\n",
      "1704: Loss: 0.41\n",
      "1705: Loss: 0.58\n",
      "1706: Loss: 0.57\n",
      "1707: Loss: 0.54\n",
      "1708: Loss: 0.58\n",
      "1709: Loss: 0.47\n",
      "1710: Loss: 0.56\n",
      "1711: Loss: 0.56\n",
      "1712: Loss: 0.69\n",
      "1713: Loss: 0.57\n",
      "1714: Loss: 0.64\n",
      "1715: Loss: 0.61\n",
      "1716: Loss: 0.57\n",
      "1717: Loss: 0.53\n",
      "1718: Loss: 0.53\n",
      "1719: Loss: 0.46\n",
      "1720: Loss: 0.49\n",
      "1721: Loss: 0.36\n",
      "1722: Loss: 0.45\n",
      "1723: Loss: 0.34\n",
      "1724: Loss: 0.42\n",
      "1725: Loss: 0.39\n",
      "1726: Loss: 0.44\n",
      "1727: Loss: 0.65\n",
      "1728: Loss: 0.35\n",
      "1729: Loss: 0.46\n",
      "1730: Loss: 0.36\n",
      "1731: Loss: 0.55\n",
      "1732: Loss: 0.43\n",
      "1733: Loss: 0.41\n",
      "1734: Loss: 0.61\n",
      "1735: Loss: 0.46\n",
      "1736: Loss: 0.35\n",
      "1737: Loss: 0.48\n",
      "1738: Loss: 0.44\n",
      "1739: Loss: 0.41\n",
      "1740: Loss: 0.40\n",
      "1741: Loss: 0.52\n",
      "1742: Loss: 0.40\n",
      "1743: Loss: 0.37\n",
      "1744: Loss: 0.52\n",
      "1745: Loss: 0.46\n",
      "1746: Loss: 0.41\n",
      "1747: Loss: 0.36\n",
      "1748: Loss: 0.37\n",
      "1749: Loss: 0.39\n",
      "1750: Loss: 0.40\n",
      "1751: Loss: 0.42\n",
      "1752: Loss: 0.43\n",
      "1753: Loss: 0.55\n",
      "1754: Loss: 0.40\n",
      "1755: Loss: 0.52\n",
      "1756: Loss: 0.36\n",
      "1757: Loss: 0.47\n",
      "1758: Loss: 0.43\n",
      "1759: Loss: 0.43\n",
      "1760: Loss: 0.49\n",
      "1761: Loss: 0.33\n",
      "1762: Loss: 0.31\n",
      "1763: Loss: 0.38\n",
      "1764: Loss: 0.33\n",
      "1765: Loss: 0.39\n",
      "1766: Loss: 0.25\n",
      "1767: Loss: 0.36\n",
      "1768: Loss: 0.36\n",
      "1769: Loss: 0.37\n",
      "1770: Loss: 0.44\n",
      "1771: Loss: 0.35\n",
      "1772: Loss: 0.33\n",
      "1773: Loss: 0.41\n",
      "1774: Loss: 0.33\n",
      "1775: Loss: 0.46\n",
      "1776: Loss: 0.29\n",
      "1777: Loss: 0.54\n",
      "1778: Loss: 0.48\n",
      "1779: Loss: 0.43\n",
      "1780: Loss: 0.32\n",
      "1781: Loss: 0.41\n",
      "1782: Loss: 0.43\n",
      "1783: Loss: 0.49\n",
      "1784: Loss: 0.47\n",
      "1785: Loss: 0.35\n",
      "1786: Loss: 0.28\n",
      "1787: Loss: 0.39\n",
      "1788: Loss: 0.51\n",
      "1789: Loss: 0.50\n",
      "1790: Loss: 0.40\n",
      "1791: Loss: 0.46\n",
      "1792: Loss: 0.30\n",
      "1793: Loss: 0.41\n",
      "1794: Loss: 0.48\n",
      "1795: Loss: 0.37\n",
      "1796: Loss: 0.38\n",
      "1797: Loss: 0.29\n",
      "1798: Loss: 0.41\n",
      "1799: Loss: 0.41\n",
      "1801: Loss: 0.36\n",
      "1802: Loss: 0.38\n",
      "1803: Loss: 0.25\n",
      "1804: Loss: 0.45\n",
      "1805: Loss: 0.37\n",
      "1806: Loss: 0.31\n",
      "1807: Loss: 0.32\n",
      "1808: Loss: 0.23\n",
      "1809: Loss: 0.33\n",
      "1810: Loss: 0.31\n",
      "1811: Loss: 0.30\n",
      "1812: Loss: 0.34\n",
      "1813: Loss: 0.34\n",
      "1814: Loss: 0.28\n",
      "1815: Loss: 0.35\n",
      "1816: Loss: 0.24\n",
      "1817: Loss: 0.32\n",
      "1818: Loss: 0.51\n",
      "1819: Loss: 0.35\n",
      "1820: Loss: 0.35\n",
      "1821: Loss: 0.33\n",
      "1822: Loss: 0.30\n",
      "1823: Loss: 0.41\n",
      "1824: Loss: 0.31\n",
      "1825: Loss: 0.37\n",
      "1826: Loss: 0.35\n",
      "1827: Loss: 0.21\n",
      "1828: Loss: 0.30\n",
      "1829: Loss: 0.24\n",
      "1830: Loss: 0.32\n",
      "1831: Loss: 0.25\n",
      "1832: Loss: 0.19\n",
      "1833: Loss: 0.36\n",
      "1834: Loss: 0.32\n",
      "1835: Loss: 0.24\n",
      "1836: Loss: 0.34\n",
      "1837: Loss: 0.31\n",
      "1838: Loss: 0.20\n",
      "1839: Loss: 0.28\n",
      "1840: Loss: 0.39\n",
      "1841: Loss: 0.26\n",
      "1842: Loss: 0.44\n",
      "1843: Loss: 0.38\n",
      "1844: Loss: 0.33\n",
      "1845: Loss: 0.31\n",
      "1846: Loss: 0.28\n",
      "1847: Loss: 0.47\n",
      "1848: Loss: 0.34\n",
      "1849: Loss: 0.45\n",
      "1850: Loss: 0.26\n",
      "1851: Loss: 0.34\n",
      "1852: Loss: 0.31\n",
      "1853: Loss: 0.34\n",
      "1854: Loss: 0.29\n",
      "1855: Loss: 0.32\n",
      "1856: Loss: 0.28\n",
      "1857: Loss: 0.20\n",
      "1858: Loss: 0.32\n",
      "1859: Loss: 0.34\n",
      "1860: Loss: 0.26\n",
      "1861: Loss: 0.27\n",
      "1862: Loss: 0.26\n",
      "1863: Loss: 0.26\n",
      "1864: Loss: 0.29\n",
      "1865: Loss: 0.22\n",
      "1866: Loss: 0.32\n",
      "1867: Loss: 0.28\n",
      "1868: Loss: 0.30\n",
      "1869: Loss: 0.20\n",
      "1870: Loss: 0.28\n",
      "1871: Loss: 0.23\n",
      "1872: Loss: 0.23\n",
      "1873: Loss: 0.32\n",
      "1874: Loss: 0.31\n",
      "1875: Loss: 0.33\n",
      "1876: Loss: 0.31\n",
      "1877: Loss: 0.30\n",
      "1878: Loss: 0.27\n",
      "1879: Loss: 0.25\n",
      "1880: Loss: 0.33\n",
      "1881: Loss: 0.25\n",
      "1882: Loss: 0.19\n",
      "1883: Loss: 0.35\n",
      "1884: Loss: 0.34\n",
      "1885: Loss: 0.29\n",
      "1886: Loss: 0.34\n",
      "1887: Loss: 0.22\n",
      "1888: Loss: 0.39\n",
      "1889: Loss: 0.32\n",
      "1890: Loss: 0.32\n",
      "1891: Loss: 0.26\n",
      "1892: Loss: 0.23\n",
      "1893: Loss: 0.35\n",
      "1894: Loss: 0.27\n",
      "1895: Loss: 0.31\n",
      "1896: Loss: 0.31\n",
      "1897: Loss: 0.30\n",
      "1898: Loss: 0.21\n",
      "1899: Loss: 0.36\n",
      "1901: Loss: 0.26\n",
      "1902: Loss: 0.31\n",
      "1903: Loss: 0.41\n",
      "1904: Loss: 0.31\n",
      "1905: Loss: 0.29\n",
      "1906: Loss: 0.27\n",
      "1907: Loss: 0.29\n",
      "1908: Loss: 0.40\n",
      "1909: Loss: 0.27\n",
      "1910: Loss: 0.31\n",
      "1911: Loss: 0.25\n",
      "1912: Loss: 0.28\n",
      "1913: Loss: 0.22\n",
      "1914: Loss: 0.24\n",
      "1915: Loss: 0.30\n",
      "1916: Loss: 0.15\n",
      "1917: Loss: 0.28\n",
      "1918: Loss: 0.36\n",
      "1919: Loss: 0.29\n",
      "1920: Loss: 0.22\n",
      "1921: Loss: 0.32\n",
      "1922: Loss: 0.24\n",
      "1923: Loss: 0.23\n",
      "1924: Loss: 0.42\n",
      "1925: Loss: 0.25\n",
      "1926: Loss: 0.18\n",
      "1927: Loss: 0.26\n",
      "1928: Loss: 0.33\n",
      "1929: Loss: 0.32\n",
      "1930: Loss: 0.40\n",
      "1931: Loss: 0.39\n",
      "1932: Loss: 0.40\n",
      "1933: Loss: 0.24\n",
      "1934: Loss: 0.19\n",
      "1935: Loss: 0.32\n",
      "1936: Loss: 0.25\n",
      "1937: Loss: 0.35\n",
      "1938: Loss: 0.18\n",
      "1939: Loss: 0.28\n",
      "1940: Loss: 0.22\n",
      "1941: Loss: 0.28\n",
      "1942: Loss: 0.17\n",
      "1943: Loss: 0.24\n",
      "1944: Loss: 0.20\n",
      "1945: Loss: 0.23\n",
      "1946: Loss: 0.20\n",
      "1947: Loss: 0.36\n",
      "1948: Loss: 0.30\n",
      "1949: Loss: 0.32\n",
      "1950: Loss: 0.25\n",
      "1951: Loss: 0.33\n",
      "1952: Loss: 0.20\n",
      "1953: Loss: 0.39\n",
      "1954: Loss: 0.24\n",
      "1955: Loss: 0.25\n",
      "1956: Loss: 0.27\n",
      "1957: Loss: 0.41\n",
      "1958: Loss: 0.33\n",
      "1959: Loss: 0.18\n",
      "1960: Loss: 0.27\n",
      "1961: Loss: 0.21\n",
      "1962: Loss: 0.29\n",
      "1963: Loss: 0.31\n",
      "1964: Loss: 0.26\n",
      "1965: Loss: 0.26\n",
      "1966: Loss: 0.30\n",
      "1967: Loss: 0.24\n",
      "1968: Loss: 0.25\n",
      "1969: Loss: 0.31\n",
      "1970: Loss: 0.47\n",
      "1971: Loss: 0.19\n",
      "1972: Loss: 0.33\n",
      "1973: Loss: 0.32\n",
      "1974: Loss: 0.29\n",
      "1975: Loss: 0.30\n",
      "1976: Loss: 0.29\n",
      "1977: Loss: 0.32\n",
      "1978: Loss: 0.34\n",
      "1979: Loss: 0.24\n",
      "1980: Loss: 0.32\n",
      "1981: Loss: 0.26\n",
      "1982: Loss: 0.33\n",
      "1983: Loss: 0.19\n",
      "1984: Loss: 0.26\n",
      "1985: Loss: 0.26\n",
      "1986: Loss: 0.28\n",
      "1987: Loss: 0.22\n",
      "1988: Loss: 0.23\n",
      "1989: Loss: 0.17\n",
      "1990: Loss: 0.28\n",
      "1991: Loss: 0.27\n",
      "1992: Loss: 0.17\n",
      "1993: Loss: 0.25\n",
      "1994: Loss: 0.39\n",
      "1995: Loss: 0.30\n",
      "1996: Loss: 0.21\n",
      "1997: Loss: 0.21\n",
      "1998: Loss: 0.20\n",
      "1999: Loss: 0.21\n",
      "2001: Loss: 0.20\n",
      "2002: Loss: 0.25\n",
      "2003: Loss: 0.28\n",
      "2004: Loss: 0.21\n",
      "2005: Loss: 0.38\n",
      "2006: Loss: 0.24\n",
      "2007: Loss: 0.17\n",
      "2008: Loss: 0.33\n",
      "2009: Loss: 0.22\n",
      "2010: Loss: 0.23\n",
      "2011: Loss: 0.34\n",
      "2012: Loss: 0.18\n",
      "2013: Loss: 0.22\n",
      "2014: Loss: 0.23\n",
      "2015: Loss: 0.17\n",
      "2016: Loss: 0.18\n",
      "2017: Loss: 0.15\n",
      "2018: Loss: 0.23\n",
      "2019: Loss: 0.15\n",
      "2020: Loss: 0.18\n",
      "2021: Loss: 0.19\n",
      "2022: Loss: 0.16\n",
      "2023: Loss: 0.18\n",
      "2024: Loss: 0.26\n",
      "2025: Loss: 0.15\n",
      "2026: Loss: 0.31\n",
      "2027: Loss: 0.25\n",
      "2028: Loss: 0.24\n",
      "2029: Loss: 0.20\n",
      "2030: Loss: 0.23\n",
      "2031: Loss: 0.21\n",
      "2032: Loss: 0.26\n",
      "2033: Loss: 0.13\n",
      "2034: Loss: 0.17\n",
      "2035: Loss: 0.23\n",
      "2036: Loss: 0.22\n",
      "2037: Loss: 0.25\n",
      "2038: Loss: 0.18\n",
      "2039: Loss: 0.11\n",
      "2040: Loss: 0.15\n",
      "2041: Loss: 0.16\n",
      "2042: Loss: 0.20\n",
      "2043: Loss: 0.22\n",
      "2044: Loss: 0.25\n",
      "2045: Loss: 0.15\n",
      "2046: Loss: 0.20\n",
      "2047: Loss: 0.24\n",
      "2048: Loss: 0.21\n",
      "2049: Loss: 0.16\n",
      "2050: Loss: 0.32\n",
      "2051: Loss: 0.15\n",
      "2052: Loss: 0.19\n",
      "2053: Loss: 0.20\n",
      "2054: Loss: 0.17\n",
      "2055: Loss: 0.13\n",
      "2056: Loss: 0.19\n",
      "2057: Loss: 0.19\n",
      "2058: Loss: 0.15\n",
      "2059: Loss: 0.13\n",
      "2060: Loss: 0.16\n",
      "2061: Loss: 0.13\n",
      "2062: Loss: 0.24\n",
      "2063: Loss: 0.17\n",
      "2064: Loss: 0.23\n",
      "2065: Loss: 0.23\n",
      "2066: Loss: 0.18\n",
      "2067: Loss: 0.12\n",
      "2068: Loss: 0.26\n",
      "2069: Loss: 0.12\n",
      "2070: Loss: 0.16\n",
      "2071: Loss: 0.18\n",
      "2072: Loss: 0.27\n",
      "2073: Loss: 0.20\n",
      "2074: Loss: 0.15\n",
      "2075: Loss: 0.17\n",
      "2076: Loss: 0.21\n",
      "2077: Loss: 0.19\n",
      "2078: Loss: 0.15\n",
      "2079: Loss: 0.19\n",
      "2080: Loss: 0.19\n",
      "2081: Loss: 0.20\n",
      "2082: Loss: 0.20\n",
      "2083: Loss: 0.23\n",
      "2084: Loss: 0.22\n",
      "2085: Loss: 0.21\n",
      "2086: Loss: 0.20\n",
      "2087: Loss: 0.19\n",
      "2088: Loss: 0.14\n",
      "2089: Loss: 0.19\n",
      "2090: Loss: 0.12\n",
      "2091: Loss: 0.30\n",
      "2092: Loss: 0.18\n",
      "2093: Loss: 0.20\n",
      "2094: Loss: 0.17\n",
      "2095: Loss: 0.23\n",
      "2096: Loss: 0.21\n",
      "2097: Loss: 0.16\n",
      "2098: Loss: 0.18\n",
      "2099: Loss: 0.13\n",
      "2101: Loss: 0.15\n",
      "2102: Loss: 0.22\n",
      "2103: Loss: 0.16\n",
      "2104: Loss: 0.12\n",
      "2105: Loss: 0.16\n",
      "2106: Loss: 0.23\n",
      "2107: Loss: 0.12\n",
      "2108: Loss: 0.15\n",
      "2109: Loss: 0.35\n",
      "2110: Loss: 0.18\n",
      "2111: Loss: 0.21\n",
      "2112: Loss: 0.27\n",
      "2113: Loss: 0.11\n",
      "2114: Loss: 0.13\n",
      "2115: Loss: 0.14\n",
      "2116: Loss: 0.21\n",
      "2117: Loss: 0.15\n",
      "2118: Loss: 0.17\n",
      "2119: Loss: 0.23\n",
      "2120: Loss: 0.14\n",
      "2121: Loss: 0.16\n",
      "2122: Loss: 0.13\n",
      "2123: Loss: 0.28\n",
      "2124: Loss: 0.20\n",
      "2125: Loss: 0.17\n",
      "2126: Loss: 0.12\n",
      "2127: Loss: 0.18\n",
      "2128: Loss: 0.16\n",
      "2129: Loss: 0.15\n",
      "2130: Loss: 0.15\n",
      "2131: Loss: 0.26\n",
      "2132: Loss: 0.18\n",
      "2133: Loss: 0.20\n",
      "2134: Loss: 0.20\n",
      "2135: Loss: 0.25\n",
      "2136: Loss: 0.18\n",
      "2137: Loss: 0.13\n",
      "2138: Loss: 0.11\n",
      "2139: Loss: 0.14\n",
      "2140: Loss: 0.16\n",
      "2141: Loss: 0.18\n",
      "2142: Loss: 0.13\n",
      "2143: Loss: 0.15\n",
      "2144: Loss: 0.19\n",
      "2145: Loss: 0.14\n",
      "2146: Loss: 0.16\n",
      "2147: Loss: 0.15\n",
      "2148: Loss: 0.12\n",
      "2149: Loss: 0.14\n",
      "2150: Loss: 0.21\n",
      "2151: Loss: 0.17\n",
      "2152: Loss: 0.19\n",
      "2153: Loss: 0.18\n",
      "2154: Loss: 0.14\n",
      "2155: Loss: 0.12\n",
      "2156: Loss: 0.16\n",
      "2157: Loss: 0.16\n",
      "2158: Loss: 0.14\n",
      "2159: Loss: 0.22\n",
      "2160: Loss: 0.14\n",
      "2161: Loss: 0.16\n",
      "2162: Loss: 0.16\n",
      "2163: Loss: 0.14\n",
      "2164: Loss: 0.16\n",
      "2165: Loss: 0.10\n",
      "2166: Loss: 0.15\n",
      "2167: Loss: 0.17\n",
      "2168: Loss: 0.14\n",
      "2169: Loss: 0.09\n",
      "2170: Loss: 0.12\n",
      "2171: Loss: 0.09\n",
      "2172: Loss: 0.17\n",
      "2173: Loss: 0.13\n",
      "2174: Loss: 0.15\n",
      "2175: Loss: 0.11\n",
      "2176: Loss: 0.11\n",
      "2177: Loss: 0.17\n",
      "Epoch 0 loss: 0.16731184720993042\n"
     ]
    }
   ],
   "source": [
    "import optax\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = optax.adam(learning_rate)\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    losses = []\n",
    "    for i, batch in enumerate(dataset):\n",
    "        loss, grad = grad_loss_fn(params, batch)\n",
    "        losses.append(loss)\n",
    "        # Update parameters\n",
    "        updates, opt_state = optimizer.update(grad, opt_state)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        if i%100:\n",
    "            print(f\"{i}: Loss: {loss:.2f}\")\n",
    "    print(f'Epoch {epoch} loss: {jnp.mean(loss)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative model designs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(params):    \n",
    "    def forward(x):\n",
    "        return x @ params\n",
    "    return forward\n",
    "\n",
    "\n",
    "def mlp2(d_in, d_out):\n",
    "    # Initialize parameters\n",
    "    params = jax.random.normal(rnd_key, (d_in, d_out))\n",
    "    def forward(x, params=params):\n",
    "        return x @ params\n",
    "    # There is no other method to get the parameters\n",
    "    return forward, params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model that takes parameters as an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "d_in, d_out = 8, 16\n",
    "x = jnp.ones((n, d_in))\n",
    "rng, rn2 = jax.random.split(rnd_key)\n",
    "params = jax.random.normal(rnd_key, (d_in, d_out))\n",
    "\n",
    "model = mlp(params)\n",
    "out = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the second model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params = mlp2(d_in, d_out)\n",
    "out2 = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert jnp.all(out == out2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
